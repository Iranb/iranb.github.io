{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"node_modules/hexo-theme-next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/logo-algolia-nebula-blue-full.svg","path":"images/logo-algolia-nebula-blue-full.svg","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/bookmark.js","path":"js/bookmark.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/comments-buttons.js","path":"js/comments-buttons.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/comments.js","path":"js/comments.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/config.js","path":"js/config.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/motion.js","path":"js/motion.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/next-boot.js","path":"js/next-boot.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/schedule.js","path":"js/schedule.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/pjax.js","path":"js/pjax.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/css/noscript.styl","path":"css/noscript.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/fancybox.js","path":"js/third-party/fancybox.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/pace.js","path":"js/third-party/pace.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/quicklink.js","path":"js/third-party/quicklink.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/rating.js","path":"js/third-party/rating.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/baidu-analytics.js","path":"js/third-party/analytics/baidu-analytics.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/google-analytics.js","path":"js/third-party/analytics/google-analytics.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/matomo.js","path":"js/third-party/analytics/matomo.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/growingio.js","path":"js/third-party/analytics/growingio.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/chatra.js","path":"js/third-party/chat/chatra.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/gitter.js","path":"js/third-party/chat/gitter.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/tidio.js","path":"js/third-party/chat/tidio.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/math/katex.js","path":"js/third-party/math/katex.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/math/mathjax.js","path":"js/third-party/math/mathjax.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/changyan.js","path":"js/third-party/comments/changyan.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/disqus.js","path":"js/third-party/comments/disqus.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/disqusjs.js","path":"js/third-party/comments/disqusjs.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/gitalk.js","path":"js/third-party/comments/gitalk.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/isso.js","path":"js/third-party/comments/isso.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/utterances.js","path":"js/third-party/comments/utterances.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/search/algolia-search.js","path":"js/third-party/search/algolia-search.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/search/local-search.js","path":"js/third-party/search/local-search.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/livere.js","path":"js/third-party/comments/livere.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/statistics/firestore.js","path":"js/third-party/statistics/firestore.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/statistics/lean-analytics.js","path":"js/third-party/statistics/lean-analytics.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/pdf.js","path":"js/third-party/tags/pdf.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/mermaid.js","path":"js/third-party/tags/mermaid.js","modified":1,"renderable":1}],"Cache":[{"_id":"source/_posts/linux.md","hash":"e6ca06f3d6c2e0af0e28a40bdc4969f41f0b6adf","modified":1652344560555},{"_id":"source/_posts/how-to-finetune.md","hash":"81f0473d321f1654a928a8dca9c95193fe4f5540","modified":1663049028902},{"_id":"source/_posts/kaggle-top-player-notes.md","hash":"86f228bad4e4d81e5fa8dfe56d0b1f6812b260a1","modified":1663046567521},{"_id":"source/_posts/mmdetection.md","hash":"bd2fb6d4408d9fd79373651fe18294c764f53ec5","modified":1663038936096},{"_id":"source/_posts/reveal-md.md","hash":"feefca7e3a6f603ca24fb7458ebc74aa29fb0251","modified":1654768836462},{"_id":"source/_posts/how-to-finetune/normlize.png","hash":"88387a86d2c3dd51c171e08a655806a615902da9","modified":1663048219809},{"_id":"node_modules/hexo-theme-next/_vendors.yml","hash":"6a7bab46b4fc9d7722e29e2dac549def0d8dcaa3","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/package.json","hash":"bbe3995c35b05028273e1def2394c3333a270654","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/docs/LICENSE.txt","hash":"f5b14f791b7cfa1d16da981d929152e088a5d1b8","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/README.md","hash":"56638e4978154a2f2a3f03ba84047b77b4a499cc","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/_config.yml","hash":"a4829c703f4ad1fc4ae16b28ffabded43af7aba1","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/LICENSE.md","hash":"68fc9a03d50fd4b5ea97092b05967d1819dea2c4","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/bn.yml","hash":"fccbf2855392186e11daa8590121073594037b7b","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/README.md","hash":"b2567e32805dda79601157351a07e5ca9fe01315","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/ar.yml","hash":"bca66db21c015dbd32970d8708b898518a773e1e","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/de.yml","hash":"4be7b8b76c81bf1853eb36d2e874b17546a0e792","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/en.yml","hash":"814d81c27fed736055ee300e0a6505b26ff4313c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/docs/AUTHORS.md","hash":"a648823121563c34a177ae91f5a774b5e29f01a0","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/id.yml","hash":"14e794db4eca36b257994d81eb513e61d1edcbd6","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/es.yml","hash":"b813da5aed9d73b809133db4dfb08f90ec56afd9","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/fr.yml","hash":"b15dc05afdc94de02e5d3fee4f8d3dc5594dd37e","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/fa.yml","hash":"6456d40dd42f44101d9d6e7054e9884e9163f948","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/it.yml","hash":"c1eeab4992c76bfd436bb205ce58b1cfeef55ee6","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/ja.yml","hash":"d48c4157e0e02e847aac7b513580d3364c81948c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/pt-BR.yml","hash":"a1f27b3a592fc58f17d247f5563ff4a90a3da5f2","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/ko.yml","hash":"819c19eb9d142e5411f77cf3821d90f740ee114a","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/pt.yml","hash":"63a3e1e728ba5e6e22150de7331bb8a654f34960","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/si.yml","hash":"615d18d044f44df476d6bfbf73f7b0edc2632168","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/tk.yml","hash":"519239e35c3bda7b62b00ff5d34644f45b16fe6a","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/nl.yml","hash":"ecb8e39c6225f3c068a5fdd569ee7dafd5c41a1f","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/uk.yml","hash":"7dd24580c0865c5a7bc4d391855045366a598936","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/zh-CN.yml","hash":"5a3ab21210304efef736e96bad254f789f42c567","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/tr.yml","hash":"0bebba73d6f06c7dad61f80c0d7ad5f6f1791a01","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/zh-HK.yml","hash":"f195bb0502ffe66e850077a1af1033455ea65f93","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/vi.yml","hash":"c669c34da544a563ceae3e196addc9df6a78e024","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/zh-TW.yml","hash":"92256b90028de9a1e79c6bc0e5885b93e7fb4b17","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_layout.njk","hash":"20e4160cd0deb4fa272cc3aed0f43520b3cf4a9c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/category.njk","hash":"c68b7343d0f8145010f93351908cc36ef6212ec1","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/index.njk","hash":"dd63e488ae8cc144335a5958acedf6a16edd7a92","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/page.njk","hash":"6c40aa438c658eb7f0cd0f6a759f18b43e7e8f93","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/tag.njk","hash":"9e16ba20c28a7f2c6bc75aa427f48122301a30aa","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/archive.njk","hash":"d759f4d2cf5ddc6875ea250113a00662c1caf6d1","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/post.njk","hash":"6abeb85fb3e4c382ed4bb6049b12a807e6226e67","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/docs/zh-CN/README.md","hash":"ccf27b9249524b9fec1c15497b4353c8d1748c6c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"7a06d443f374bd1e84294067a0ac796afd9fbe60","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/docs/zh-CN/CONTRIBUTING.md","hash":"a089f7a8368ab0b7d7b9b7ec0ac3767a453435df","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/docs/ru/README.md","hash":"6c82bfd2ec8248c248da701f091b548a7a133580","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/images/logo.svg","hash":"2cb74fd3ea2635e015eabc58a8d488aed6cf6417","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/bookmark.js","hash":"0f563ffbf05fad30e854e413ab17ff7164ab5a53","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/images/logo-algolia-nebula-blue-full.svg","hash":"b85e274207b1392782476a0430feac98db1e7da0","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/comments.js","hash":"66ae2e26ea36a41b72c638ea8b220296638ae952","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/comments-buttons.js","hash":"1a7344440321713426a0b2ab17e276b5bdf85ade","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/motion.js","hash":"f7c825cbff11885fa0dffa64824fd00e505d6a8d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/languages/ru.yml","hash":"8c2b6361f2de17561c1a3eede2bf47b4e2ba6ce5","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/schedule.js","hash":"a1333258726caf84f368a8f8454639c7dc1626bb","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/next-boot.js","hash":"da0f07f9eaaa83de70128b0feaea3fdadb90457a","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/pjax.js","hash":"919f5281c4a04d11cfd94573ecf57b3dbabd3cc8","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/events/index.js","hash":"3ce10d4cce94e3d4c482c2e18bb6f0f0ca380d3d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/filters/default-injects.js","hash":"872f01cb10e422a648ea505436532e776e92926b","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/filters/minify.js","hash":"f160e39943e39d7276da86adb47c3f08e5f22c7a","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/filters/locals.js","hash":"9eb5310664759931287dd28ea39165dfb67f12ed","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/filters/post.js","hash":"30e03a1d4828259f82d46e64cbfe2955b6cff9a9","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/helpers/next-vendors.js","hash":"afdd6a188a74c188f0dd154fac70efd4080ca262","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/helpers/navigation.js","hash":"78107021101553c3d23e89290f7530b60cf4aa86","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/helpers/next-config.js","hash":"226fccbe9c93265e65a300e3cb4bf6f9065cfdd7","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/images/avatar.gif","hash":"2dbc3e2f2d624b2ca1afe6edc2ca17307f1950c8","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/helpers/next-url.js","hash":"a11b71ba0c5012e2cdcab31c15439156b215563e","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/tags/button.js","hash":"c6ad2ed544fbb25ecb5d820c36e76302504271b7","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/tags/caniuse.js","hash":"935a311142a409c1896b3ae3f01fe7a9e2db1134","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/tags/center-quote.js","hash":"92c19d796bdb3320df9caea59bf52df7a95d9da9","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/helpers/font.js","hash":"3394185a7f0393c16ce52c8028f90da3e9239c55","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/tags/index.js","hash":"17f9451ce1f10f78437f52218757d38d4e1591b0","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/tags/group-pictures.js","hash":"9ed799c329abf830f623689d7e136991256a24ca","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/tags/link-grid.js","hash":"18a483c2d5afd701f6080ffdddf2d1321370336c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/tags/label.js","hash":"8a73348186113bae0a51ea2f891c1bb882fab05a","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/tags/mermaid.js","hash":"4fb01ca650fa8b256b8d48f50dc1b18350bd3d6d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/tags/pdf.js","hash":"344636b6fd7e27e8831c1e194039afc0d61931cd","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/tags/tabs.js","hash":"0eabe51da40b4b13e16419c8fe02452d9a4fef73","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/tags/video.js","hash":"2ee926448583be8f95af1f2884ae2c9c4830151d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/tags/note.js","hash":"7b94ddb46b7d4b0fe815f2fbe4bd375f07f55363","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/helpers/engine.js","hash":"d292b78485e8e8055712b0ed6de7cf559c5fbdcd","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/utils.js","hash":"200088bfd042f5304b2a04befab0829148845e0e","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_mixins.styl","hash":"32d31cb5a155681c19f5ad0bb56dcb08429f93ef","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_scripts/vendors.njk","hash":"be80b9fe415a9a09d74c28e230995fd292dfc123","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/noscript.styl","hash":"263eddabfae40e54c0591e7baa8403ade8cdd56d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_scripts/index.njk","hash":"6668878a0f9a1166c6a879755f54a08d942da870","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/main.styl","hash":"78ce791cc4ac95386cf6839ca72f5f7b51f86ee9","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/config.js","hash":"4c4ebbe3b3f3841a26f9d5af6d0ba8bc6da01c54","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_macro/sidebar.njk","hash":"eb786e8b35e354287cda345c524cd35ec955f692","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_colors.styl","hash":"3c6798c10cc220d83481cb3f3782e78558cee789","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/comments.njk","hash":"d0c470b0f6690aa217e9ada848c5e2e73fb27c6f","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_macro/post.njk","hash":"434b3e76a040a816169e1929657e4176e7b8164c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/pagination.njk","hash":"9876dbfc15713c7a47d4bcaa301f4757bd978269","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/widgets.njk","hash":"852a750524decf1efa587cd52b09e387ed8315de","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/index.njk","hash":"d41eeb262978e34de4679d8971a9e7ac5d90ecbc","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/fancybox.njk","hash":"844559f46e2ff1c8be234d5763703106e2072a7b","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/footer.njk","hash":"19713f472972caac33ae5fbcfe9105da61257de4","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/rating.njk","hash":"1bcdbc7fde26d6d9ef4e7fa43ffcff5a9506b20e","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/languages.njk","hash":"e43f22198cccb5f6e306b1ce0d28d12a4fb891f8","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/quicklink.njk","hash":"0efed71ed530447718c4ea5bbd5fc8695b0b0d5f","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/fancybox.js","hash":"c098d14e65dd170537134358d4b8359ad0539c2c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_macro/post-collapse.njk","hash":"1a30d751871dabfa80940042ddb1f77d07d830b9","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/pace.js","hash":"0ef04218b93561ba4d0ff420d556c3d90a756d32","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/quicklink.js","hash":"eed02e6fced8e5a653077205d4d4d7834ca71472","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/rating.js","hash":"4e92c2d107ba47b47826829f9668030d5ea9bfb8","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/highlight.js","hash":"6aec7b2c38c50989a23bfaa0d560e75c7f553e12","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/navigation.js","hash":"dd3562686d95a50375e6fd32e717ccb0d99c1e3d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/vendors.js","hash":"64e4024376b51fe81be7ad80235abdf0a83853bd","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/changyan.js","hash":"7fa8701c86485b2fe7324e017101a32417902397","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/default-config.js","hash":"93ee5f9109dad885dc38c49bcee630c10f9dce6e","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/common.js","hash":"19a402a225c31edffc50f202a14e0d582d3db23e","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/disqus.js","hash":"7f71d6b271ba65ff333d5682e7575711d368c0d2","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/config.js","hash":"c8b59b404f5d2a0b3b5cd1a6c9a10af5f30e43b5","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/disqusjs.js","hash":"62faf6b0b0020066a0dec1f0123cf1fee3198e7e","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/gitalk.js","hash":"7bb7dafdd7f6bca8464b54e17e552ce7f1714195","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/isso.js","hash":"ff8b5b5145220a17d0ecd9508ba9bd2d3b2da47d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/livere.js","hash":"5a07d8bb52bc1d51a624ca8db54be144566c306b","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/utils.js","hash":"ec996d0673f766167c86df0966e9da1ae036e103","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/utterances.js","hash":"d3bded697bc32dace689d2a6dfb6eb7514169d15","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/injects.js","hash":"d987709267a1bc6e5014411e9983d7c49c102c16","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/schemes/muse.js","hash":"9794bd4fc6a458322949d6a0ade89cd1026bc69f","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/pace.njk","hash":"d7ad5714079f7f65446f880baf14722435ca9061","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_variables/Pisces.styl","hash":"c65536a128b9bc9dbe2fbb1b235a3cded2891002","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_variables/base.styl","hash":"163c7441d777bee87042d475e6ce0fde199add28","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_variables/Gemini.styl","hash":"96e0a7c2a65ce68215e17e369085b2ea2f1334f2","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_variables/Mist.styl","hash":"e1fbf169b9b6a194b518240cbd06ec3c48b83d61","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_variables/Muse.styl","hash":"e3be898f5ebcf435a26542653a9297ff2c71aeb0","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/brand.njk","hash":"aff4613756456be26415febc668860fdab8d33c5","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/head/head-unique.njk","hash":"8da52a144060db1a0a088ccb2e6cc8376d1fce70","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/index.njk","hash":"650de421a8ce4cf685428ffbe0087ff84cbd1356","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/sub-menu.njk","hash":"06480d8ec5f0b87eafd47f082f07968d7282dd5c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/menu-item.njk","hash":"41a8b0cc16f60fa085cb719d07216d86b6bc4bf8","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/head/head.njk","hash":"0ba2bf0266f1fcb8edbd961869f8521b29685c56","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/menu.njk","hash":"ee6fc2f111572d3eeab0a2fecbb2d6b3e37ab26b","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/schedule.njk","hash":"0f4bc8e257da60f77c0c1738607b2bde55810684","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/breadcrumb.njk","hash":"89825e75cc45e9709fa6ba89883669eedaff6f46","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/categories.njk","hash":"17156d99941f28a225951ffdcfa9a115e20dc2d2","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/page-header.njk","hash":"7ed4f102a1825195cff8d7995bf9219f323a9034","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/tags.njk","hash":"a18d1598e36cc72f2b0b24c3cc3c5990dfaa3254","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-followme.njk","hash":"154df0bb323c332d8c25343f258ee865e5553423","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-copyright.njk","hash":"133942922e34abae9e4de7ea5591d77c0caa4b37","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-reward.njk","hash":"002b51d0cae3f2e2e008bdc58be90c728282de5b","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-related.njk","hash":"57eca76cfbbe9a65bc2a77f1deebf003ed335673","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-meta.njk","hash":"9fa47e4fb342811da590ee4adc91cf81118c0a39","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/search/index.njk","hash":"8f6f256ab3b351ffc80f1f3f1d9834e9a7cfac31","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-footer.njk","hash":"bde2c7356d9362972bde41cc206d5816f8ed714d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/search/algolia-search.njk","hash":"efb2b6f19df02ba5ae623a1f274fff52aed21e6f","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/sidebar/site-overview.njk","hash":"3d8591bb92df77ceb9d5b07bc76da1ca89e5bd76","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/baidu-analytics.njk","hash":"6215309aee028dcb734452beec448c5afb6c63fc","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/cloudflare.njk","hash":"a5b8297c2c383124dd6a56e256ecc0c0dcf489be","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_partials/search/localsearch.njk","hash":"661f7acae43f0be694266323320f977d84119abe","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/index.njk","hash":"314805f0186e9f6208c845f0757fdb7891c540f6","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/microsoft-clarity.njk","hash":"9dc00fcb0a05899f048eace9f9160b78956655d5","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/growingio.njk","hash":"8afaa772c390bd9d53a5cff9645ac3168334eb98","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/matomo.njk","hash":"4e89648a8ec8194c5823064cbca39c938a799006","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/google-analytics.njk","hash":"d89066ff53879693f023e540d59c86137172c529","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/chat/chatra.njk","hash":"d7263fca16d0278ccf1f6aa1c6df6902a6344a09","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/chat/tidio.njk","hash":"02aab857c27fc103216029be991688b12a73a525","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/chat/gitter.njk","hash":"f8cc14b7aa949999a1faaeb7855e2f20b59a386d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/changyan.njk","hash":"d1c950f8fbdf85e7a3eae5463767a89e858e8220","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/utterances.njk","hash":"5a94032bc3512a10ad4328fc19ec07b819a1d687","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/livere.njk","hash":"3b13b09fba84ec6000886890a6710736a2b8fafe","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/disqusjs.njk","hash":"0749cb6902baecdfd01f779a2a2513f6d2f6a823","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/disqus.njk","hash":"9375b19a89b7fa9474e558d085af5448d4c5c50c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/math/katex.njk","hash":"1ebf658690468ea197bdd0416eb7cfa4bd0b083a","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/math/mathjax.njk","hash":"3677017fd4572b158311f5f5d870590ab25184e0","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/math/index.njk","hash":"abf37fc55aa86702118e8fdf5bf2d389dd589aa0","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/gitalk.njk","hash":"b63b7e2ede0d3e66e732fa1a06bda9b19e1e85d4","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/isso.njk","hash":"64cc3bdaf644fd32c0d0a247f29f5b6904da9af3","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/statistics/busuanzi-counter.njk","hash":"a4bc501da0f22f7e420f0ca47e83988ce90b1368","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/search/localsearch.njk","hash":"e45ea3542cdc9ed7ec8447b5e6f35df4c5e82758","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/search/algolia-search.njk","hash":"24ed76e0c72a25ac152820c750a05826a706b6f4","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/statistics/index.njk","hash":"568ddf7955d11d93fb5e842b403a7ac8b1b7fdb1","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/statistics/firestore.njk","hash":"d32ebe94560fa95824478ebbff531bffc47b194d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/statistics/lean-analytics.njk","hash":"2446e748cdc102c78492216319ac02148db7daf6","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/tags/pdf.njk","hash":"2c81984cc4f5123103460442f6e046f5b6c97127","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/layout/_third-party/tags/mermaid.njk","hash":"099e031f52fb8e47b3af5b2684737efc9e643ee7","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/google-analytics.js","hash":"59684383385059dc4f8a1ff85dbbeb703bcdbcb5","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/growingio.js","hash":"78dd3cf04082b7dbe6246e404b2aa8e726922402","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/matomo.js","hash":"c6a25b26a1443caa70b47fd3dfa282271574deb5","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/baidu-analytics.js","hash":"f629acc46ff40c071ffd31b77d5c7616f0fdd778","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/math/mathjax.js","hash":"5c749b9c1c3bb738122d0516211ecff6496d4907","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/gitter.js","hash":"cc38c94125f90dadde11b5ebac7d8bf99a1a08a2","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/math/katex.js","hash":"83c54ee536e487a1031783443fe0cb63b1b4767e","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/changyan.js","hash":"260d1a77d6a3bb33a579d3e4cca1997003e799b5","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/chatra.js","hash":"c32180522788c10e51df1803aa6842ef0432ddc9","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/tidio.js","hash":"b0079f6a4601e06ca6fe46e83a2f5af553e9bc3c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/search/algolia-search.js","hash":"fdb7b7cef1a147d897e7f7cd8903b58368ec2062","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/disqus.js","hash":"e1cc671b0d524864fd445e3ab4ade9ee6d07e565","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/disqusjs.js","hash":"33a82207a15aad9d1c8fb2251f9e3eba50452932","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/gitalk.js","hash":"0ec038cf83e8ec067534f16a54041e47a3c1e59a","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/utterances.js","hash":"f67f90eb03e284c82da2b8cf2f1e31801813c16d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/livere.js","hash":"2247d88c934c765c43013337860774aaa99f0b31","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/isso.js","hash":"753a873b6f566aff5ba77ca23f91b78eb880ca64","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/statistics/firestore.js","hash":"411a72df581f5b21317dc28633c7993207eb9e1c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/search/local-search.js","hash":"4536cb6d0a9bbaaa86fab3fa0101f6a3a3ec5a76","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/pdf.js","hash":"af78c22f0e61c8c8aa8794e585e0d632c6d4fcb8","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/index.styl","hash":"fe1868f47681e00a33a96199302be85377282f63","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/mermaid.js","hash":"f27d817b0c2138dd3215b1f46af0753f60a008f3","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/js/third-party/statistics/lean-analytics.js","hash":"835cbf54c49ef1327f47df70ff2636ad36b6f57d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/reading-progress.styl","hash":"90a86045a33c1bae49fc2f6fa1e1b53170c7f77b","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/index.styl","hash":"8e34df131830d4fa3725e4590a672ba1cf1903e5","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/back-to-top.styl","hash":"bab653bcf226311381e8411a0492202f1bf1fce9","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/mobile.styl","hash":"64775c729512b30b144ab5ae9dc4a4dfd4e13f35","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/index.styl","hash":"523fb7b653b87ae37fc91fc8813e4ffad87b0d7e","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/comments.styl","hash":"e4fecc889ba3317a64e9abba5842c79dff9b7827","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/base.styl","hash":"d0a7c99095f490b0d2ed6b1be43d435960798cec","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tables.styl","hash":"e840b23d33023e6d45e018f6e84b683dd56efd8d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/toggles.styl","hash":"572a41499391677d84b16d8dbd6a996a3d5ce041","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/_header.styl","hash":"4817e77577896ab5c0da434549917ee703a3f4cf","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/buttons.styl","hash":"a042571d85ff7265f799004239a45f36b716b8a6","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Gemini/index.styl","hash":"fd49b521d67eaccc629f77b4e095cb7310327565","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/_posts-expand.styl","hash":"be6cf377ae8f4a01ee76f9b3014e74161d4d5d17","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/_menu.styl","hash":"fb550935d374e0bdf1097fce187337dc05cad3e1","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/_layout.styl","hash":"5604ac1e161099a4d3e5657d53507268866dc717","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_layout.styl","hash":"82a29572dd90451f75358a2ee2522b87304a0bb8","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_header.styl","hash":"06080fd963c904d96c00eff098a284e337953013","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/index.styl","hash":"ab16a3dcdc0393b9b582ef59dcc13db9320e917c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_sidebar.styl","hash":"944364893bd7160d954c10ba931af641c91515a4","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_sub-menu.styl","hash":"c48ccd8d6651fe1a01faff8f01179456d39ba9b1","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_menu.styl","hash":"b7f48be3c43bfa393d62142544a5487a67871713","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_header.styl","hash":"b741ab96e73370711c63a6581159f2ea8b5bfa1b","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_sidebar.styl","hash":"d9141e6e14a56b5952488101e9a8388c2170e270","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"778ed2ad5643b93970c95626b325defeb586733f","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_layout.styl","hash":"6eee86c8f0175d6c09e434053516cd8556f78d44","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_menu.styl","hash":"72dc825c50357402c342d62ab60fc0c478ab6bc1","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/normalize.styl","hash":"b56367ea676ea8e8783ea89cd4ab150c7da7a060","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/pagination.styl","hash":"b5c7782368889fa9fd93807d28ff2daf270e3703","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/index.styl","hash":"8000075b227749a7495eaf417cac6ccfbe441580","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/categories.styl","hash":"b6e2eb1550a7845cb2adf86081a4ab6c7bde1e68","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/breadcrumb.styl","hash":"8afdc311c6b8db121758371f95cf1c5e77354f42","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/tag-cloud.styl","hash":"1a81d1a71fcf0699629ce6e72dfd0a15f3a2dd0a","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/schedule.styl","hash":"6b816c2511242ee503fb5f34cd3e4dcdafc06b85","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/index.styl","hash":"7504dbc5c70262b048143b2c37d2b5aa2809afa2","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/disqusjs.styl","hash":"c2326ee3e8b724d99c24a818ddee32813ea5bf89","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/gitter.styl","hash":"35104dc6883a61c31e0e368dac8ac2f697be62fe","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/math.styl","hash":"9d995eb4871a6c273d9d51558676a1fdabf69e72","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/gitalk.styl","hash":"070737d101e7cd58e997e8c7af09958268c43a21","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/related-posts.styl","hash":"41ed817e1eb64078074e245e771446ee041e5790","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/index.styl","hash":"979486a41a81f2a9fd8b0b87c4f87d6416c68c7d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-collapse.styl","hash":"ec37a36e94ba791663607a5022f763915778578f","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/search.styl","hash":"e72799ce3f9b79753e365b2f8c8ef6c310668d4a","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/footer/index.styl","hash":"8b9407e5cfd0571ef8de7df19022b268f962fa2f","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/utterances.styl","hash":"56d90ae0559caa55b75f3c300ff2711f9ed65fc4","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-gallery.styl","hash":"aa366d37389760c8595529b850f461569577a1c5","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-footer.styl","hash":"1d284f3ea03ba9b4feb76b375e539a8e0bccf1c3","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-body.styl","hash":"d757768a58743601d0d84158ba955eb15d4c3c01","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/index.styl","hash":"d0805a763176b3c0003967401644f41dfe3bc9e8","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-followme.styl","hash":"fc1a7bac6493f24aa50665574f37f3dd954f210c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-nav.styl","hash":"9ac6f477177264c26a46e8333b8456720a0444dc","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-reward.styl","hash":"07cff69f2d57e6321595f64c16d8b763dc88df6a","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-header.styl","hash":"010c901e4ef49a606f8a350efbf09044e76d2ff3","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/bookmark.styl","hash":"e74f4bb47a101b014ee2a1783c87f3b87323f9a0","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-widgets.styl","hash":"b6677dc2a2368084ab82bb4f145ac79e5966c150","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/github-banner.styl","hash":"38c64c2d04e46848382bfa246a0e9c508294767b","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/index.styl","hash":"ff642130354a0b3be0d708c43044ed4d710b5e83","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/site-meta.styl","hash":"759e582d34d08e3386c55d87a835a9523608619f","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/menu.styl","hash":"392fd53a8dd4e3f33a853ebb24290a622300e0ff","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"5b38ac4a0f1ade0e681aff0e3366c481d9cf3dcd","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"52fc98b1435129eb3edb9293ced9e507741f1350","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"b926e368f702f8686aaa2eb98d3d2e533418958c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"9950c3188a28e1c63b5498b7bdcd14b12ace3e28","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/index.styl","hash":"cee43480eba028c37d51cb620c2d81486aa24e01","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"fbdb63c6a8887d19b7137325ba7d6806f728139c","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/site-nav.styl","hash":"bf3ad8b4268f763a1e26377681644887694bc009","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"3103b81fc76b59e1e2c161e2c484625c770ed66f","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"021a37cf178440cc341940a299d3bca359996c6b","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"ee94a1a27090ad24e3ed579093088d97ff96d77d","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/highlight/index.styl","hash":"f2328caa94645836e06fb39a6a9c9a84ed68a8b5","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"670fc109b56a010b166b86b616823a1aae97a738","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/site-state.styl","hash":"26dd0adfcb1db6df29c6090c8d7e9b5a43583fb0","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/index.styl","hash":"3f76c73a891bbc10679753e702feba9e8a5ffdd2","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/label.styl","hash":"debee14539272fbe3835a7d3853af2230baa3501","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/note.styl","hash":"d27fbf7799695295dd5860a161a13ac4d90c5ba4","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"393ff96234e4196b569d4b11496774eb78e147de","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"d6418fd2bbfba7b73ddf11ec62db9637fdf5d8af","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/pdf.styl","hash":"b6654a1d7cf82577d8263faffee8af3ad4a5c0e8","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/mermaid.styl","hash":"48d35dba575a7c9e8845b16652e76b7d4a4646de","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/tabs.styl","hash":"7a39bcce7274284e87388743db62afc847fe6897","modified":1663037947552},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/link-grid.styl","hash":"7f8a7345e6537a62cd9e9a94c8f7065b541d9b04","modified":1663037947552}],"Category":[],"Data":[],"Page":[],"Post":[{"uuid":"c725aa10-3309-11ed-b601-97e98cfc4594","title":"how_to_finetune","date":"2022-09-13T02:14:20.000Z","mathjax":true,"_content":"总结一些深度模型常用的调试优化技巧。\n## 0x01 探索性数据分析 EDA(Exploratory Data Analysis)\n\n## 0x02 正则化(Exploratory Data Analysis)\n1. 常用方法\n    - Z score Normalization（mean std Standardization）\n    $$\n       \\frac{x-\\overline{x}}{\\sigma} \n    $$\n    - Min-Max Scaling\n    - Standard Deviation Method\n    - Range Method\n2. 为什么需要使用正则化方法\n    - For Cluster Analysis：通常情况需要度量不同输入间的距离，未正则化数据可能会存在特殊极值影响度量结果。\n    - For Principal Component Analysis：PCA gives more weightage to those variables that have higher variances than to those variables that have very low variances（方差会影响降维结果）\n    - 正则化能改变输入数据的分布，在数据预处理时通常包含两个步骤：Scaling & Normalize， Scaling负责将输入数据映射到0-1范围内，Scaling can help compare different variables on equal footing（在同样的步长上比较两个数据）; Normalization本质上是一种激进的策略，The point of normalization is to change your observations so that they can be described as a normal distribution.Normalization能够改变模型观察数据的角度，使输入数据可以被描述为一个正态分布。\n    - Scaling(归一化)消除特征间单位和尺度差异的影响，以对每维特征同等看待，需要对特征进行归一化。\n    - 因尺度差异，其损失函数的等高线图可能是椭圆形，梯度方向垂直于等高线,变换后，其损失函数的等高线图更接近圆形，梯度下降的方向震荡更小，收敛更快\n    - 随着训练程度加深，模型复杂度会增加，偏差减少，方差增大，而泛化误差呈现 U 型变化，对于一个“好的系统”通常要求误差小，正则化的作用即为适当的控制模型复杂度，从而使得泛化误差曲线取最小值![如图](normlize.png)，从贝叶斯角度考虑，正则项等价于引入参数的模型先验概率，可以简单理解为对最大似然估计（MLE）引入先验概率，从而转化为最大后验估计（MAP），其中的先验概率即对于正则项\n## 0x03: 如何选择CNN输入图像的尺寸\n\n\n## 0xFF: References\n\n\\[1]: [Class-balanced-loss-pytorch](https://github.com/vandit15/Class-balanced-loss-pytorch)\n[2]: [When and why to standardize or normalize a variable?](https://www.kaggle.com/discussions/questions-and-answers/59305)\n[3]: [Data Cleaning Challenge: Scale and Normalize Data](https://www.kaggle.com/code/rtatman/data-cleaning-challenge-scale-and-normalize-data/notebook)\n[4]: [CNN Input Size Explained](https://www.kaggle.com/competitions/siim-isic-melanoma-classification/discussion/160147)","source":"_posts/how-to-finetune.md","raw":"---\nuuid: c725aa10-3309-11ed-b601-97e98cfc4594\ntitle: how_to_finetune\ndate: 2022-09-13 10:14:20\ntags: pytorch\nmathjax: true\n---\n总结一些深度模型常用的调试优化技巧。\n## 0x01 探索性数据分析 EDA(Exploratory Data Analysis)\n\n## 0x02 正则化(Exploratory Data Analysis)\n1. 常用方法\n    - Z score Normalization（mean std Standardization）\n    $$\n       \\frac{x-\\overline{x}}{\\sigma} \n    $$\n    - Min-Max Scaling\n    - Standard Deviation Method\n    - Range Method\n2. 为什么需要使用正则化方法\n    - For Cluster Analysis：通常情况需要度量不同输入间的距离，未正则化数据可能会存在特殊极值影响度量结果。\n    - For Principal Component Analysis：PCA gives more weightage to those variables that have higher variances than to those variables that have very low variances（方差会影响降维结果）\n    - 正则化能改变输入数据的分布，在数据预处理时通常包含两个步骤：Scaling & Normalize， Scaling负责将输入数据映射到0-1范围内，Scaling can help compare different variables on equal footing（在同样的步长上比较两个数据）; Normalization本质上是一种激进的策略，The point of normalization is to change your observations so that they can be described as a normal distribution.Normalization能够改变模型观察数据的角度，使输入数据可以被描述为一个正态分布。\n    - Scaling(归一化)消除特征间单位和尺度差异的影响，以对每维特征同等看待，需要对特征进行归一化。\n    - 因尺度差异，其损失函数的等高线图可能是椭圆形，梯度方向垂直于等高线,变换后，其损失函数的等高线图更接近圆形，梯度下降的方向震荡更小，收敛更快\n    - 随着训练程度加深，模型复杂度会增加，偏差减少，方差增大，而泛化误差呈现 U 型变化，对于一个“好的系统”通常要求误差小，正则化的作用即为适当的控制模型复杂度，从而使得泛化误差曲线取最小值![如图](normlize.png)，从贝叶斯角度考虑，正则项等价于引入参数的模型先验概率，可以简单理解为对最大似然估计（MLE）引入先验概率，从而转化为最大后验估计（MAP），其中的先验概率即对于正则项\n## 0x03: 如何选择CNN输入图像的尺寸\n\n\n## 0xFF: References\n\n\\[1]: [Class-balanced-loss-pytorch](https://github.com/vandit15/Class-balanced-loss-pytorch)\n[2]: [When and why to standardize or normalize a variable?](https://www.kaggle.com/discussions/questions-and-answers/59305)\n[3]: [Data Cleaning Challenge: Scale and Normalize Data](https://www.kaggle.com/code/rtatman/data-cleaning-challenge-scale-and-normalize-data/notebook)\n[4]: [CNN Input Size Explained](https://www.kaggle.com/competitions/siim-isic-melanoma-classification/discussion/160147)","slug":"how-to-finetune","published":1,"updated":"2022-09-13T06:03:48.902Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl7zsi80s0000v0t0fcghdifr"},{"uuid":"88501be0-3313-11ed-89cc-1381c123a077","title":"kaggle top player notes","date":"2022-09-13T03:24:10.000Z","mathjax":true,"_content":"记录一些kaggle top player 的笔记\n## [Dieter](https://www.kaggle.com/christofhenkel): Deep Learning Data Scientist at Nvidia\n1. Ensemble, bag of models\nDieter 使用了7个模型，集合albumentations的图像放缩\n    - 2x seresnext101 - SmallMaxSize(512) -> RandomCrop(448,448)\n    - 1x seresnext101 - Resize(686,686) -> RandomCrop(568,568)\n    - 1x b3 - LongestMaxSize(512) -> PadIfNeeded -> RandomCrop(448,448)\n    - 1x b3 - LongestMaxSize(664) -> PadIfNeeded -> RandomCrop(600,600)\n    - 1x resnet152 - Resize(544,672) -> RandomCrop(512,512)\n    - 1x res2net101 - Resize(544,672) -> RandomCrop(512,512)\n2. 使用imagenet dataset的 mean 和 std 正则化输入图像\n3. 使用了GeM pooling\nGeM pooling 中包含一个网络参数p，随着学习过程使得网络自适应学习选择偏重平均池化或是最大池化，p=1时gem为平均池化, $p \\rightarrow + \\infty$ 时为最大池化，P越大越关注局部越小越关注全局\n    - 最大池化更多的保留的纹理特征，局部特征。\n    - 平均池化更多保留的背景信息，全局特征。\n4. 学习率： warmup + cosine annealing scheduler ","source":"_posts/kaggle-top-player-notes.md","raw":"---\nuuid: 88501be0-3313-11ed-89cc-1381c123a077\ntitle: kaggle top player notes\ndate: 2022-09-13 11:24:10\ntags:\nmathjax: true\n---\n记录一些kaggle top player 的笔记\n## [Dieter](https://www.kaggle.com/christofhenkel): Deep Learning Data Scientist at Nvidia\n1. Ensemble, bag of models\nDieter 使用了7个模型，集合albumentations的图像放缩\n    - 2x seresnext101 - SmallMaxSize(512) -> RandomCrop(448,448)\n    - 1x seresnext101 - Resize(686,686) -> RandomCrop(568,568)\n    - 1x b3 - LongestMaxSize(512) -> PadIfNeeded -> RandomCrop(448,448)\n    - 1x b3 - LongestMaxSize(664) -> PadIfNeeded -> RandomCrop(600,600)\n    - 1x resnet152 - Resize(544,672) -> RandomCrop(512,512)\n    - 1x res2net101 - Resize(544,672) -> RandomCrop(512,512)\n2. 使用imagenet dataset的 mean 和 std 正则化输入图像\n3. 使用了GeM pooling\nGeM pooling 中包含一个网络参数p，随着学习过程使得网络自适应学习选择偏重平均池化或是最大池化，p=1时gem为平均池化, $p \\rightarrow + \\infty$ 时为最大池化，P越大越关注局部越小越关注全局\n    - 最大池化更多的保留的纹理特征，局部特征。\n    - 平均池化更多保留的背景信息，全局特征。\n4. 学习率： warmup + cosine annealing scheduler ","slug":"kaggle-top-player-notes","published":1,"updated":"2022-09-13T05:22:47.521Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl7zsi80v0001v0t013747vd5"},{"uuid":"8d49e0a0-d1ce-11ec-9ef4-1d0b46b503d4","title":"linux","date":"2022-05-12T08:36:00.000Z","_content":"","source":"_posts/linux.md","raw":"---\nuuid: 8d49e0a0-d1ce-11ec-9ef4-1d0b46b503d4\ntitle: linux\ndate: 2022-05-12 16:36:00\ntags:\n---\n","slug":"linux","published":1,"updated":"2022-05-12T08:36:00.555Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl7zsi80w0003v0t01l1n49qf"},{"uuid":"137500a0-d5b3-11ec-8fdb-3db4a824d9de","title":"reveal-md","date":"2022-05-17T07:29:24.000Z","toc":true,"_content":"\n*Reveal-md*经常用于组会汇报和一些非正式场景的PPT实现中，生成的PPT或是展示用结果由markdown组成，并且具有默认的布局样式和一些功能丰富的插件，大大简化了生成汇报用PPT的工作量。\n\n其主要格式控制由两部分组成，一部分是构成其内容主体的markdown文件，另一部分是控制页面布局的css文件（一般不需要修改）。其渲染引擎使用的是*reveal.js*，通常情况下不需要对*reveal.js*进行修改（甚至基本的配置都不需要更改）。创作PPT的过程简化为了专注于内容，构建讲述逻辑，简而言之就是填充需要的内容即可。这里不过多介绍，可[参考这里](https://github.com/webpro/reveal-md)了解更多。这篇笔记的主要内容是对一些疑难问题的记录。\n\n1. 样式控制\n**Reveal-md**中的全局样式需要在命令行中指定样式文件和使用的主题，样式文件需要指定其具体位置，运行时可以使用 **--css** 和 **--theme** 指定。**-w** 表示监听文件变化，并随时刷新内容。\n{% codeblock run_file lang:bash line_number:false %}\nreveal-md ppt.md -w --theme simple --css styles/base.css\n{% endcodeblock %}\n\n- 字体控制\n通常情况下，PPT中的中文字体使用<font face=\"Microsoft Yahei\">**微软雅黑**</font>，英文字体使用<font face=\"Times New Roman\">**Times NewRoman**</font>, 在**Reveal-md**中，字体样式可以由全局的样式文件控制，这里只给出一些基本的样式定义。通过对html中所有元素的字体进行设置，可以得到全局的样式文件，同时，由于添加了 **!important**，其样式不会被后续的设置覆盖。同样这种方式可以设置PPT中的默认字体大小。**reveal-md**中的默认字体对我来说有点太大了。\n{% codeblock style/style.css lang:css line_number:false %}\nhtml * {\n    font-family: \"Times New Roman\", Times, \"Microsoft Yahei\" !important;\n}\n{% endcodeblock %}\n\nreveal 中预定义了几种字体大小，可以根据实际需求进行修改\n\n{% codeblock ppt.md lang:html line_number:false %}\nfont-size:medium|xx-small|x-small|small|large|x-large|xx-large|smaller|larger|length|initial|inherit;\n{% endcodeblock %}\n\n2. 图像或内容居中设置\n这里有两种方式，一种是全局的图像或者文字进行样式设置进行居中，另一种是创建独立的div块，对块中的内容进行居中，这里使用css优先级可以对其中的元素进行单独更新，首先在全局文件中默认左对齐，之后根据实际需求在markdown文件中再对需要的部分进行修改即可。在**Reveal-md**中，单独的文字或段落会被渲染成<p></p>标签的形式，因此只需要对其样式进行修改即可。\n{% codeblock style/style.css lang:css line_number:false %}\np.left {\n    text-align: left;\n    width: 100%;\n}\n{% endcodeblock %}\n关于其他元素的居中设置，可以设置一个居中的div块，对块中的内容进行居中即可。实现方式如下：\n{% codeblock style/style.css lang:css line_number:false %}\n.center-div {\n    text-align: center;\n    /*让div内部文字居中*/\n    width: 700px;\n    height: 200px;\n    margin: auto;\n}\n{% endcodeblock %}","source":"_posts/reveal-md.md","raw":"---\nuuid: 137500a0-d5b3-11ec-8fdb-3db4a824d9de\ntitle: reveal-md\ndate: 2022-05-17 15:29:24\ntags: ppt\ntoc: true\n---\n\n*Reveal-md*经常用于组会汇报和一些非正式场景的PPT实现中，生成的PPT或是展示用结果由markdown组成，并且具有默认的布局样式和一些功能丰富的插件，大大简化了生成汇报用PPT的工作量。\n\n其主要格式控制由两部分组成，一部分是构成其内容主体的markdown文件，另一部分是控制页面布局的css文件（一般不需要修改）。其渲染引擎使用的是*reveal.js*，通常情况下不需要对*reveal.js*进行修改（甚至基本的配置都不需要更改）。创作PPT的过程简化为了专注于内容，构建讲述逻辑，简而言之就是填充需要的内容即可。这里不过多介绍，可[参考这里](https://github.com/webpro/reveal-md)了解更多。这篇笔记的主要内容是对一些疑难问题的记录。\n\n1. 样式控制\n**Reveal-md**中的全局样式需要在命令行中指定样式文件和使用的主题，样式文件需要指定其具体位置，运行时可以使用 **--css** 和 **--theme** 指定。**-w** 表示监听文件变化，并随时刷新内容。\n{% codeblock run_file lang:bash line_number:false %}\nreveal-md ppt.md -w --theme simple --css styles/base.css\n{% endcodeblock %}\n\n- 字体控制\n通常情况下，PPT中的中文字体使用<font face=\"Microsoft Yahei\">**微软雅黑**</font>，英文字体使用<font face=\"Times New Roman\">**Times NewRoman**</font>, 在**Reveal-md**中，字体样式可以由全局的样式文件控制，这里只给出一些基本的样式定义。通过对html中所有元素的字体进行设置，可以得到全局的样式文件，同时，由于添加了 **!important**，其样式不会被后续的设置覆盖。同样这种方式可以设置PPT中的默认字体大小。**reveal-md**中的默认字体对我来说有点太大了。\n{% codeblock style/style.css lang:css line_number:false %}\nhtml * {\n    font-family: \"Times New Roman\", Times, \"Microsoft Yahei\" !important;\n}\n{% endcodeblock %}\n\nreveal 中预定义了几种字体大小，可以根据实际需求进行修改\n\n{% codeblock ppt.md lang:html line_number:false %}\nfont-size:medium|xx-small|x-small|small|large|x-large|xx-large|smaller|larger|length|initial|inherit;\n{% endcodeblock %}\n\n2. 图像或内容居中设置\n这里有两种方式，一种是全局的图像或者文字进行样式设置进行居中，另一种是创建独立的div块，对块中的内容进行居中，这里使用css优先级可以对其中的元素进行单独更新，首先在全局文件中默认左对齐，之后根据实际需求在markdown文件中再对需要的部分进行修改即可。在**Reveal-md**中，单独的文字或段落会被渲染成<p></p>标签的形式，因此只需要对其样式进行修改即可。\n{% codeblock style/style.css lang:css line_number:false %}\np.left {\n    text-align: left;\n    width: 100%;\n}\n{% endcodeblock %}\n关于其他元素的居中设置，可以设置一个居中的div块，对块中的内容进行居中即可。实现方式如下：\n{% codeblock style/style.css lang:css line_number:false %}\n.center-div {\n    text-align: center;\n    /*让div内部文字居中*/\n    width: 700px;\n    height: 200px;\n    margin: auto;\n}\n{% endcodeblock %}","slug":"reveal-md","published":1,"updated":"2022-06-09T10:00:36.462Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl7zsi80x0004v0t0dpu5can3"},{"uuid":"f9ebbe00-d1cd-11ec-8c1a-6f2de37cae84","title":"mmdetection","date":"2022-05-12T08:31:53.000Z","_content":"\n总结一些mmdetection 中常用代码及学习技巧\n\n1. 外部引用保持代码结构整洁\n\n在mmdetection中的config可以直接引用自定义文件夹中的代码，因此可以做到代码重用，保持目录的整洁。当前github上复用mmdetection代码开发实现的相关代码仓库中大多引用了不必要的代码，因此考虑从结构上简化。其中 *allow_failed_imports=False* 会在impoort的文件不存在的时候throw error。\n\n{% codeblock mmdetection/config/solo.py lang:python line_number:false %}\ncustom_imports = dict(\n    imports=[\n        \"custommd.models.detectors.single_stage_ins\",\n        \"custommd.models.detectors.solov2\",\n        \"custommd.models.solov2.mask_feat_head\",\n        \"custommd.models.solov2.solov2_head\",\n    ],\n    allow_failed_imports=False)\n{% endcodeblock %}\n\n2. 使用Wandb监控实验\n\nmmdetection框架中的wandb日志实现策略在[github](https://github.com/open-mmlab/mmcv/blob/83df7c4b00197b40c3debdb7f388a256640e13b4/mmcv/runner/hooks/logger/wandb.py)中能够找到,关于wandb的初始化参数可以参考[这里](https://docs.wandb.ai/ref/python/init), 配置文件中可以在*wandb_init_kwargs*中定义wandb的初始化参数。\n{% codeblock mmdetection/config/model_config.py lang:python line_number:false %}\nimport wandb\n\n...\n\nlog_config = dict(\n            interval=10,\n            hooks=[\n                dict(type='WandbLogger',\n                     wandb_init_kwargs={\n                         'entity': WANDB_ENTITY,\n                         'project': WANDB_PROJECT_NAME\n                     },\n                     logging_interval=10,\n                     log_checkpoint=True,\n                     log_checkpoint_metadata=True,\n                     num_eval_images=100)\n            ])\n{% endcodeblock %}\n\n3. 使用timm中预训练的backbone\n\nmmdetection 中可以使用部分timm模型作为特征提取器，但是使用有所限制。使用timm库中的特征提取器需要指定使用的backbone类型。TIMMBackbone类型的具体定义在*mmcls.models*中。有两种方式可以实现，第一种是安装mmcls包后，使用其对TIMMBackbone的定义方式，显示的在config中的backbone部分制定，另一部分则是将[basebackbone.py](https://raw.githubusercontent.com/open-mmlab/mmclassification/master/mmcls/models/backbones/base_backbone.py)文件和[timm_backbone.py](https://github.com/open-mmlab/mmclassification/blob/master/mmcls/models/backbones/timm_backbone.py)稍作修改，主要是对其中的get_root_logger()函数修改为修改为`from mmdet.utils import get_root_logger`,通过这两种引用方式可以实现在mmdetection中使用timm库中的预训练模型。默认情况下不使用预训练的权重，需要显式指定。支持更改权重所在的位置，可以使用在image21-k上预训练的模型权重。具体代码如下：\n\n{% codeblock mmdetection/config/model_config.py lang:python line_number:false %}\ncustom_imports = dict(imports=['mmcls.models'], allow_failed_imports=False)\n\"\"\"\ncustom_imports = dict(imports=[\n    'mmdet.model.backbone.timm_backbone'\n    ], allow_failed_imports=False)\n\"\"\"\n\n\nmodel = dict(\n    backbone=dict(\n        _delete_=True,\n        type='mmcls.TIMMBackbone',\n        model_name='tv_resnet50',  # ResNet-50 with torchvision weights\n        features_only=True,\n        pretrained=True,\n        checkpoint_path='',\n        out_indices=(1, 2, 3, 4)))\n{% endcodeblock %}\n\n4. 自定义**Pipeline**\nmmdetection中Pipeline决定了数据加载到送入模型前的数据处理过程，同时，Pipeline本身具有一定的灵活性，这里推荐结合 [albumentations](https://github.com/albumentations-team/albumentations) 进行数据预处理，包含对bbox 的处理过程，保证增强后的图片和标签的一致性。各种增强方法图像变换前后的对比可以[参考这里](https://albumentations-demo.herokuapp.com/)\n{% codeblock mmdetection/custom_models/albumentations.py lang:python line_number:false %}\nimport random\nfrom mmcls.datasets import PIPELINES\nimport albumentations as A\n\n@PIPELINES.register_module()\nclass RandomAlbumentationsV2(object):\n    def __init__(self, p=0.6) -> None:\n        self.p = p\n        self.transform = A.Compose([\n            A.RandomGridShuffle(always_apply=False, p=self.p, grid=(2, 2)),\n            A.CoarseDropout(\n                always_apply=False, p=1,\n                max_holes=16,\n                max_height=8,\n                max_width=8,\n            ),\n            A.Downscale(\n                always_apply=False, p=self.p,\n                scale_min=0.25, scale_max=0.25, interpolation=0\n            ),\n\n            A.ISONoise(\n                always_apply=False, p=0.9,\n                intensity=(0.0, 0.5),\n                color_shift=(0.0, 0.5),\n            ),\n             A.JpegCompression(\n                always_apply=False, p=self.p,\n                quality_lower=80,\n                quality_upper=100\n            ),\n            A.MotionBlur(\n                always_apply=False, p=self.p, \n                blur_limit=(3, 10),\n            ),\n            A.MultiplicativeNoise(\n                always_apply=False, p=1.0, multiplier=(0.1, 2.0),\n                per_channel=True,\n                elementwise=True\n            )\n\n        ])\n    def __call__(self, results):\n        img = results['img']\n        transformed = self.transform(image=img)\n        results['img'] = transformed[\"image\"]\n        return results\n\n{% endcodeblock %}\nPipeline 定义完成后，在config相应数据处理config片段中加入定义好的预处理方法即可\n{% codeblock mmdetection/config/custom_config.py lang:python line_number:false %}\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='Resize',size=224),\n    dict(type='RandomAlbumentationsV2'), # 这里为自定义pipeline的名称，可在dict内添加对应的参数\n    dict(type='RandomNoise'),\n    dict(type='RandomFlip'),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='ImageToTensor', keys=['img']),\n    dict(type='ToTensor', keys=['gt_label']),\n    dict(type='Collect', keys=['img', 'gt_label'])\n]\n{% endcodeblock %}\n检查Pipeline是否正确，这里可以使用mmdetection自带的工具对pipeline处理后的图像进行可视化处理。\n{% codeblock mmdetection/show_pipeline.sh lang:bash line_number:false %}\npython tools/visualizations/vis_pipeline.py [config_path] --output-dir [out_dir_path] --number 20 --mode concat\n{% endcodeblock %}\n\n5. 自动保存最好的ckpt文件\nmmdetection中在evaluation epoch中可按照相应的结果保存相应指标最好的权重文件，且可设置训练多少epoch时开始保存。其自带的权重保存机制支持限制保存文件的最大数量。对应代码如下：\n{% codeblock mmdetection/config/custom_config.py lang:python line_number:false %}\ncheckpoint_config = dict(interval=50, max_keep_ckpts=2) # 每50 epoch 保存一次，保存目录中最多存在两个权重文件，evaluation生成文件不包含在限制内\nevaluation = dict(       # evaluation hook 的配置\n    interval=4,          # 验证期间的间隔，单位为 epoch 或者 iter， 取决于 runner 类型。\n    metric='accuracy',\n    save_best='auto',\n    start=50\n    )   # 验证期间使用的指标。\n{% endcodeblock %}\n\n6. 梯度累计\n训练真实使用的batchsize为 samples_per_gpu * cumulative_iters，此项设置会影响模型训练的流程，最好不使用。\n{% codeblock mmdetection/config/custom_config.py lang:python line_number:false %}\noptimizer_config = dict(\n    type=\"GradientCumulativeOptimizerHook\", # 累积倍数\n    cumulative_iters=4,\n)\ndata =dict(\n    samples_per_gpu=64, # 基础batchsize\n）\n{% endcodeblock %}\n\n7. 学习率调节和可视化\nmmdetection中有几种内置的学习速率调节策略，基本通用型为使用CosineAnnealing且随epoch不断变化的学习速率设置。如下代码，target_ratio决定了最大和最小两次的学习率倍数，这里设置学习率随着epoch不断变化。\n{% codeblock mmdetection/config/custom_config.py lang:python line_number:false %}\nlr_config = dict(\n    policy='cyclic',\n    target_ratio= (2e3, 1e-2), # 决定了最大学习率倍数，实际最大值为 target_ratio[0] * lr\n    cyclic_times= 5, # 训练开始到训练结束共调整五次\n    step_ratio_up= 0.4, # real lr = warmup_ratio * initial lr\n)\n\noptimizer = dict(\n    type='AdamW',\n    lr=5e-4 * 128 * 4 / 512 * 1e-4, # 决定了 baselr\n    weight_decay=0.0001,\n    eps=1e-8,\n    betas=(0.9, 0.999),)\n{% endcodeblock %}\nmmdetection中自带学习率可视化工具，可以根据config文件对学习率可视化，方便调整。\n{% codeblock mmdetection/show_lr.sh lang:bash line_number:false %}\npython tools/visualizations/vis_lr.py [config_path] --save-path [output_path]\n{% endcodeblock %}\n\n8. Mixup & CutPaste\nmmcls中支持两个比较特殊的数据增强策略，Mixup 和 CutPaste,通常结合 LabelSmoothLoss。\n{% codeblock mmdetection/config/resnet.py lang:python line_number:false %}\nmodel = dict(\n    backbone = ...,\n    neck = ...,\n    head = ...,\n    train_cfg=dict(augments=[\n        dict(type='BatchMixup', alpha=0.8, prob=0.5, num_classes=num_classes),\n        dict(type='BatchCutMix', alpha=1.0, prob=0.5, num_classes=num_classes),\n    ]))\n)\n{% endcodeblock %}\n9. 多卡 batch norm同步设置\n有两种可用的batch norm sync 设置，MMSyncBN和SyncBN,MMSyncBN为实验功能，缺少相关文档介绍。\n{% codeblock mmdetection/config/base.py lang:python line_number:false %}\nnorm_cfg=dict(type='MMSyncBN', requires_grad=True) # or type='SyncBN'\n{% endcodeblock %}\n","source":"_posts/mmdetection.md","raw":"---\nuuid: f9ebbe00-d1cd-11ec-8c1a-6f2de37cae84\ntitle: mmdetection\ndate: 2022-05-12 16:31:53\ntags: pytorch\n---\n\n总结一些mmdetection 中常用代码及学习技巧\n\n1. 外部引用保持代码结构整洁\n\n在mmdetection中的config可以直接引用自定义文件夹中的代码，因此可以做到代码重用，保持目录的整洁。当前github上复用mmdetection代码开发实现的相关代码仓库中大多引用了不必要的代码，因此考虑从结构上简化。其中 *allow_failed_imports=False* 会在impoort的文件不存在的时候throw error。\n\n{% codeblock mmdetection/config/solo.py lang:python line_number:false %}\ncustom_imports = dict(\n    imports=[\n        \"custommd.models.detectors.single_stage_ins\",\n        \"custommd.models.detectors.solov2\",\n        \"custommd.models.solov2.mask_feat_head\",\n        \"custommd.models.solov2.solov2_head\",\n    ],\n    allow_failed_imports=False)\n{% endcodeblock %}\n\n2. 使用Wandb监控实验\n\nmmdetection框架中的wandb日志实现策略在[github](https://github.com/open-mmlab/mmcv/blob/83df7c4b00197b40c3debdb7f388a256640e13b4/mmcv/runner/hooks/logger/wandb.py)中能够找到,关于wandb的初始化参数可以参考[这里](https://docs.wandb.ai/ref/python/init), 配置文件中可以在*wandb_init_kwargs*中定义wandb的初始化参数。\n{% codeblock mmdetection/config/model_config.py lang:python line_number:false %}\nimport wandb\n\n...\n\nlog_config = dict(\n            interval=10,\n            hooks=[\n                dict(type='WandbLogger',\n                     wandb_init_kwargs={\n                         'entity': WANDB_ENTITY,\n                         'project': WANDB_PROJECT_NAME\n                     },\n                     logging_interval=10,\n                     log_checkpoint=True,\n                     log_checkpoint_metadata=True,\n                     num_eval_images=100)\n            ])\n{% endcodeblock %}\n\n3. 使用timm中预训练的backbone\n\nmmdetection 中可以使用部分timm模型作为特征提取器，但是使用有所限制。使用timm库中的特征提取器需要指定使用的backbone类型。TIMMBackbone类型的具体定义在*mmcls.models*中。有两种方式可以实现，第一种是安装mmcls包后，使用其对TIMMBackbone的定义方式，显示的在config中的backbone部分制定，另一部分则是将[basebackbone.py](https://raw.githubusercontent.com/open-mmlab/mmclassification/master/mmcls/models/backbones/base_backbone.py)文件和[timm_backbone.py](https://github.com/open-mmlab/mmclassification/blob/master/mmcls/models/backbones/timm_backbone.py)稍作修改，主要是对其中的get_root_logger()函数修改为修改为`from mmdet.utils import get_root_logger`,通过这两种引用方式可以实现在mmdetection中使用timm库中的预训练模型。默认情况下不使用预训练的权重，需要显式指定。支持更改权重所在的位置，可以使用在image21-k上预训练的模型权重。具体代码如下：\n\n{% codeblock mmdetection/config/model_config.py lang:python line_number:false %}\ncustom_imports = dict(imports=['mmcls.models'], allow_failed_imports=False)\n\"\"\"\ncustom_imports = dict(imports=[\n    'mmdet.model.backbone.timm_backbone'\n    ], allow_failed_imports=False)\n\"\"\"\n\n\nmodel = dict(\n    backbone=dict(\n        _delete_=True,\n        type='mmcls.TIMMBackbone',\n        model_name='tv_resnet50',  # ResNet-50 with torchvision weights\n        features_only=True,\n        pretrained=True,\n        checkpoint_path='',\n        out_indices=(1, 2, 3, 4)))\n{% endcodeblock %}\n\n4. 自定义**Pipeline**\nmmdetection中Pipeline决定了数据加载到送入模型前的数据处理过程，同时，Pipeline本身具有一定的灵活性，这里推荐结合 [albumentations](https://github.com/albumentations-team/albumentations) 进行数据预处理，包含对bbox 的处理过程，保证增强后的图片和标签的一致性。各种增强方法图像变换前后的对比可以[参考这里](https://albumentations-demo.herokuapp.com/)\n{% codeblock mmdetection/custom_models/albumentations.py lang:python line_number:false %}\nimport random\nfrom mmcls.datasets import PIPELINES\nimport albumentations as A\n\n@PIPELINES.register_module()\nclass RandomAlbumentationsV2(object):\n    def __init__(self, p=0.6) -> None:\n        self.p = p\n        self.transform = A.Compose([\n            A.RandomGridShuffle(always_apply=False, p=self.p, grid=(2, 2)),\n            A.CoarseDropout(\n                always_apply=False, p=1,\n                max_holes=16,\n                max_height=8,\n                max_width=8,\n            ),\n            A.Downscale(\n                always_apply=False, p=self.p,\n                scale_min=0.25, scale_max=0.25, interpolation=0\n            ),\n\n            A.ISONoise(\n                always_apply=False, p=0.9,\n                intensity=(0.0, 0.5),\n                color_shift=(0.0, 0.5),\n            ),\n             A.JpegCompression(\n                always_apply=False, p=self.p,\n                quality_lower=80,\n                quality_upper=100\n            ),\n            A.MotionBlur(\n                always_apply=False, p=self.p, \n                blur_limit=(3, 10),\n            ),\n            A.MultiplicativeNoise(\n                always_apply=False, p=1.0, multiplier=(0.1, 2.0),\n                per_channel=True,\n                elementwise=True\n            )\n\n        ])\n    def __call__(self, results):\n        img = results['img']\n        transformed = self.transform(image=img)\n        results['img'] = transformed[\"image\"]\n        return results\n\n{% endcodeblock %}\nPipeline 定义完成后，在config相应数据处理config片段中加入定义好的预处理方法即可\n{% codeblock mmdetection/config/custom_config.py lang:python line_number:false %}\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='Resize',size=224),\n    dict(type='RandomAlbumentationsV2'), # 这里为自定义pipeline的名称，可在dict内添加对应的参数\n    dict(type='RandomNoise'),\n    dict(type='RandomFlip'),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='ImageToTensor', keys=['img']),\n    dict(type='ToTensor', keys=['gt_label']),\n    dict(type='Collect', keys=['img', 'gt_label'])\n]\n{% endcodeblock %}\n检查Pipeline是否正确，这里可以使用mmdetection自带的工具对pipeline处理后的图像进行可视化处理。\n{% codeblock mmdetection/show_pipeline.sh lang:bash line_number:false %}\npython tools/visualizations/vis_pipeline.py [config_path] --output-dir [out_dir_path] --number 20 --mode concat\n{% endcodeblock %}\n\n5. 自动保存最好的ckpt文件\nmmdetection中在evaluation epoch中可按照相应的结果保存相应指标最好的权重文件，且可设置训练多少epoch时开始保存。其自带的权重保存机制支持限制保存文件的最大数量。对应代码如下：\n{% codeblock mmdetection/config/custom_config.py lang:python line_number:false %}\ncheckpoint_config = dict(interval=50, max_keep_ckpts=2) # 每50 epoch 保存一次，保存目录中最多存在两个权重文件，evaluation生成文件不包含在限制内\nevaluation = dict(       # evaluation hook 的配置\n    interval=4,          # 验证期间的间隔，单位为 epoch 或者 iter， 取决于 runner 类型。\n    metric='accuracy',\n    save_best='auto',\n    start=50\n    )   # 验证期间使用的指标。\n{% endcodeblock %}\n\n6. 梯度累计\n训练真实使用的batchsize为 samples_per_gpu * cumulative_iters，此项设置会影响模型训练的流程，最好不使用。\n{% codeblock mmdetection/config/custom_config.py lang:python line_number:false %}\noptimizer_config = dict(\n    type=\"GradientCumulativeOptimizerHook\", # 累积倍数\n    cumulative_iters=4,\n)\ndata =dict(\n    samples_per_gpu=64, # 基础batchsize\n）\n{% endcodeblock %}\n\n7. 学习率调节和可视化\nmmdetection中有几种内置的学习速率调节策略，基本通用型为使用CosineAnnealing且随epoch不断变化的学习速率设置。如下代码，target_ratio决定了最大和最小两次的学习率倍数，这里设置学习率随着epoch不断变化。\n{% codeblock mmdetection/config/custom_config.py lang:python line_number:false %}\nlr_config = dict(\n    policy='cyclic',\n    target_ratio= (2e3, 1e-2), # 决定了最大学习率倍数，实际最大值为 target_ratio[0] * lr\n    cyclic_times= 5, # 训练开始到训练结束共调整五次\n    step_ratio_up= 0.4, # real lr = warmup_ratio * initial lr\n)\n\noptimizer = dict(\n    type='AdamW',\n    lr=5e-4 * 128 * 4 / 512 * 1e-4, # 决定了 baselr\n    weight_decay=0.0001,\n    eps=1e-8,\n    betas=(0.9, 0.999),)\n{% endcodeblock %}\nmmdetection中自带学习率可视化工具，可以根据config文件对学习率可视化，方便调整。\n{% codeblock mmdetection/show_lr.sh lang:bash line_number:false %}\npython tools/visualizations/vis_lr.py [config_path] --save-path [output_path]\n{% endcodeblock %}\n\n8. Mixup & CutPaste\nmmcls中支持两个比较特殊的数据增强策略，Mixup 和 CutPaste,通常结合 LabelSmoothLoss。\n{% codeblock mmdetection/config/resnet.py lang:python line_number:false %}\nmodel = dict(\n    backbone = ...,\n    neck = ...,\n    head = ...,\n    train_cfg=dict(augments=[\n        dict(type='BatchMixup', alpha=0.8, prob=0.5, num_classes=num_classes),\n        dict(type='BatchCutMix', alpha=1.0, prob=0.5, num_classes=num_classes),\n    ]))\n)\n{% endcodeblock %}\n9. 多卡 batch norm同步设置\n有两种可用的batch norm sync 设置，MMSyncBN和SyncBN,MMSyncBN为实验功能，缺少相关文档介绍。\n{% codeblock mmdetection/config/base.py lang:python line_number:false %}\nnorm_cfg=dict(type='MMSyncBN', requires_grad=True) # or type='SyncBN'\n{% endcodeblock %}\n","slug":"mmdetection","published":1,"updated":"2022-09-13T03:15:36.096Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl7zsi80x0005v0t00gqzb7fk"}],"PostAsset":[{"_id":"source/_posts/how-to-finetune/normlize.png","post":"cl7zsi80s0000v0t0fcghdifr","slug":"normlize.png","modified":1,"renderable":1}],"PostCategory":[],"PostTag":[{"post_id":"cl7zsi80s0000v0t0fcghdifr","tag_id":"cl7zsi80w0002v0t08ob03ynl","_id":"cl7zsi80y0007v0t036bs6sha"},{"post_id":"cl7zsi80x0005v0t00gqzb7fk","tag_id":"cl7zsi80w0002v0t08ob03ynl","_id":"cl7zsi80y0008v0t00c7hddmz"},{"post_id":"cl7zsi80x0004v0t0dpu5can3","tag_id":"cl7zsi80y0006v0t0ex4f2htr","_id":"cl7zsi80y0009v0t019uy8439"}],"Tag":[{"name":"pytorch","_id":"cl7zsi80w0002v0t08ob03ynl"},{"name":"ppt","_id":"cl7zsi80y0006v0t0ex4f2htr"}]}}