<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ML concept</title>
    <url>/2022/09/20/ML-concept/</url>
    <content><![CDATA[<h2 id="x01归纳偏置inductive-bias">0x01归纳偏置（inductive bias）</h2>
<ol type="1">
<li>定义</li>
</ol>
<ul>
<li>指的是学习算法中，当学习器去预测其未遇到过的输入结果时，所做的一些假设的集合</li>
<li>模型在预测训练中未出现的样本时，若无任何约束未知样本可以是对应任意的结果，若没有其它额外的假设，问题就无法解决。</li>
<li>关于目标函数的必要假设就称为归纳偏置</li>
</ul>
<ol start="2" type="1">
<li>归纳偏置种类
<ul>
<li>最大条件独立性</li>
<li>最小交叉验证误差</li>
<li>最大边界</li>
<li>最小描述长度</li>
<li>最少特征数</li>
<li>最近邻居</li>
</ul></li>
<li>虽然大部分的学习算法使用固定的偏置，但有些算法在获得更多数据时可以变换它们的偏置。这不会取消偏置，因为偏置变换的过程本身就是一种偏置。</li>
</ol>
<h2 id="xff-reference">0xFF Reference</h2>
<p>[1]: <a href="https://zh.wikipedia.org/wiki/%E5%BD%92%E7%BA%B3%E5%81%8F%E7%BD%AE">归纳偏置
wiki</a></p>
]]></content>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ Guide</title>
    <url>/2022/09/26/CPP/</url>
    <content><![CDATA[<ol type="1">
<li>CMakeLists.txt 包含<strong>CMak</strong>命令
<ul>
<li>minimum version
<code>cmake_minimum_required(VERSION 3.5)</code></li>
<li>指定项目名称 <code>project (hello_cmake)</code></li>
<li>指定输出二进制文件对应的c++文件<code>add_executable(hello_cmake main.cpp)</code>
可以通过环境变量<code>CMAKE_BINARY_DIR</code>设置二进制文件的输出位置</li>
<li>执行<code>cmake .</code>或 <code>cmake ..</code>
命令会自动寻找路径下的CmakeLists.txt 文件，并执行其中的内容</li>
<li>执行 <code>make</code>
可以输出二进制文件，且可以指定参数如<code>make VERBOSE=1</code>会进入debug模式，终端会输出更多细节。</li>
<li>引入外部的 include 文件夹,
<ul>
<li><em>PRIVATE</em>
表示文件夹会被加入到targets对应的include文件夹下</li>
<li><em>INTERFACE</em> 表示目录会被添加到任意引用这个文件的include
文件夹内部</li>
<li><em>PUBLIC</em>
会同时包括<em>PRIVATE</em>和<em>INTERFACE</em>的功能，同时任意的target也可以链接到这个库内
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">target_include_directories(target</span><br><span class="line">    PRIVATE</span><br><span class="line">        ${PROJECT_SOURCE_DIR}/include</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><code>.a</code>文件表示静态库文件，由以下函数生成</li>
</ul></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">add_library(hello_library STATIC</span><br><span class="line">    src/Hello.cpp</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="xff-reference">0XFF Reference</h2>
<p>【1】https://github.com/ttroy50/cmake-examples</p>
]]></content>
  </entry>
  <entry>
    <title>kaggle top player notes</title>
    <url>/2022/09/13/kaggle-top-player-notes/</url>
    <content><![CDATA[<p>记录一些kaggle top player 的笔记 ## <a href="https://www.kaggle.com/christofhenkel">Dieter</a>: Deep Learning
Data Scientist at Nvidia 1. Ensemble, bag of models Dieter
使用了7个模型，集合albumentations的图像放缩 - 2x seresnext101 -
SmallMaxSize(512) -&gt; RandomCrop(448,448) - 1x seresnext101 -
Resize(686,686) -&gt; RandomCrop(568,568) - 1x b3 - LongestMaxSize(512)
-&gt; PadIfNeeded -&gt; RandomCrop(448,448) - 1x b3 -
LongestMaxSize(664) -&gt; PadIfNeeded -&gt; RandomCrop(600,600) - 1x
resnet152 - Resize(544,672) -&gt; RandomCrop(512,512) - 1x res2net101 -
Resize(544,672) -&gt; RandomCrop(512,512) 2. 使用imagenet dataset的 mean
和 std 正则化输入图像 3. 使用了GeM pooling GeM pooling
中包含一个网络参数p，随着学习过程使得网络自适应学习选择偏重平均池化或是最大池化，p=1时gem为平均池化,
<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="8.68ex" height="1.758ex" role="img" focusable="false" viewbox="0 -583 3836.6 777"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g><g data-mml-node="mo" transform="translate(780.8,0)"><path data-c="2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"/></g><g data-mml-node="mo" transform="translate(2058.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"/></g><g data-mml-node="mi" transform="translate(2836.6,0)"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"/></g></g></g></svg></mjx-container></span>
时为最大池化，P越大越关注局部越小越关注全局 -
最大池化更多的保留的纹理特征，局部特征。 -
平均池化更多保留的背景信息，全局特征。 4. 学习率： warmup + cosine
annealing scheduler</p>
]]></content>
  </entry>
  <entry>
    <title>how_to_finetune</title>
    <url>/2022/09/13/how-to-finetune/</url>
    <content><![CDATA[<p>总结一些深度模型常用的调试优化技巧。</p>
<h2 id="x01-探索性数据分析-edaexploratory-data-analysis">0x01
探索性数据分析 EDA(Exploratory Data Analysis)</h2>
<ol type="1">
<li>数据分布分析
主要判断训练数据中存在的各类数据与其样本占训练数据占比，通常存在两种分布：均匀分布和长尾分布
## 0x02 正则化</li>
<li>常用方法
<ul>
<li>Z score Normalization（mean std Standardization）</li>
</ul></li>
</ol>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.577ex;" xmlns="http://www.w3.org/2000/svg" width="6.349ex" height="4.824ex" role="img" focusable="false" viewbox="0 -1435 2806.4 2132"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(794.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/></g><g data-mml-node="mover" transform="translate(1794.4,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(0,374)"><svg width="572" height="237" x="0" y="148" viewbox="143 148 572 237"><path data-c="2013" d="M0 248V285H499V248H0Z" transform="scale(1.716,1)"/></svg></g></g></g><g data-mml-node="mi" transform="translate(1117.7,-686)"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"/></g><rect width="2566.4" height="60" x="120" y="220"/></g></g></g></svg></mjx-container></span></p>
<pre><code>- Min-Max Scaling
- Standard Deviation Method
- Range Method
- RankGauss(top1-recon)
通常RankGauss的效果也会比标准化和归一化好</code></pre>
<figure class="highlight python"><figcaption><span>mmdetection/rankgauss</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> erfinv</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scale_minmax</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="string">'''归一化'''</span></span><br><span class="line">    <span class="keyword">return</span> (x - x.<span class="built_in">min</span>()) / (x.<span class="built_in">max</span>() - x.<span class="built_in">min</span>())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scale_norm</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="string">'''标准化'''</span></span><br><span class="line">    <span class="keyword">return</span> (x - x.mean()) / x.std()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scale_rankgauss</span>(<span class="params">x, epsilon=<span class="number">1e-6</span></span>):</span><br><span class="line">    <span class="string">'''rankgauss'''</span></span><br><span class="line">    x = x.argsort().argsort() <span class="comment"># rank</span></span><br><span class="line">    x = (x/x.<span class="built_in">max</span>()-<span class="number">0.5</span>)*<span class="number">2</span> <span class="comment"># scale</span></span><br><span class="line">    x = np.clip(x, -<span class="number">1</span>+epsilon, <span class="number">1</span>-epsilon)</span><br><span class="line">    x = erfinv(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>为什么需要使用正则化方法
<ul>
<li>For Cluster
Analysis：通常情况需要度量不同输入间的距离，未正则化数据可能会存在特殊极值影响度量结果。</li>
<li>For Principal Component Analysis：PCA gives more weightage to those
variables that have higher variances than to those variables that have
very low variances（方差会影响降维结果）</li>
<li>正则化能改变输入数据的分布，在数据预处理时通常包含两个步骤：Scaling
&amp; Normalize， Scaling负责将输入数据映射到0-1范围内，Scaling can help
compare different variables on equal
footing（在同样的步长上比较两个数据）;
Normalization本质上是一种激进的策略，The point of normalization is to
change your observations so that they can be described as a normal
distribution.Normalization能够改变模型观察数据的角度，使输入数据可以被描述为一个正态分布。</li>
<li>Scaling(归一化)消除特征间单位和尺度差异的影响，以对每维特征同等看待，需要对特征进行归一化。</li>
<li>因尺度差异，其损失函数的等高线图可能是椭圆形，梯度方向垂直于等高线,变换后，其损失函数的等高线图更接近圆形，梯度下降的方向震荡更小，收敛更快</li>
<li>随着训练程度加深，模型复杂度会增加，偏差减少，方差增大，而泛化误差呈现
U
型变化，对于一个“好的系统”通常要求误差小，正则化的作用即为适当的控制模型复杂度，从而使得泛化误差曲线取最小值<img src="/2022/09/13/how-to-finetune/normlize.png" alt="如图">，从贝叶斯角度考虑，正则项等价于引入参数的模型先验概率，可以简单理解为对最大似然估计（MLE）引入先验概率，从而转化为最大后验估计（MAP），其中的先验概率即对于正则项
## 0x03: 如何选择CNN输入图像的尺寸</li>
</ul></li>
<li>ImageNet
上预训练的backbone模型通常在224x224大小的输入图像上进行预训练，这并不意味着我们需要将输入图像resize到224x224大小</li>
<li>以224x224大小的输入数据为例，假设输入图像经过网络输出的特征图大小为原始图像的<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.816ex;" xmlns="http://www.w3.org/2000/svg" width="2.595ex" height="2.773ex" role="img" focusable="false" viewbox="0 -864.9 1147.1 1225.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mn" transform="translate(396.8,394) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="mn" transform="translate(220,-345) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"/><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"/></g><rect width="907.1" height="60" x="120" y="220"/></g></g></g></svg></mjx-container></span>,如果将输入图像尺寸增大到512x512,则对应的输出特征图大小从7x7变为16x16，特征图的输出大小仅与网络本身结构和输入的图像大小有关。</li>
<li>在模型中，与预训练尺寸有关的是网络从确定大小物体中学习到的固定模式，例如从输入图像中寻找直径为50个像素大小的圆，或是边长为30个像素的三角形。以下三个图为例
<img src="/2022/09/13/how-to-finetune/FLower.png" alt="FLower"> <img src="/2022/09/13/how-to-finetune/car.png" alt="car">
<img src="/2022/09/13/how-to-finetune/dogs.png" alt="Dogs"></li>
<li>假设将输入图像大小放大到512x512会发生什么：放缩输入图像的大小等价于放缩图像中的物体，CNN可能找不到直径50的圆和边长30的三角形。
<img src="/2022/09/13/how-to-finetune/result_512.jpg" alt="result_512">
如果图像尺寸缩小到128，模型可能找不到其中的圆 <img src="/2022/09/13/how-to-finetune/result_128.jpg" alt="result_128"></li>
<li>结论
CNN能从图像中搜索固定的模式（patterns），这些固定的模式可能和图像的尺寸相关，因此需要通过实验寻找不同模式对应的inputsize，
或者融合多尺度特征。 ## 0x04 DataAugmentation</li>
<li>CutMix 公式如下: <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="75.566ex" height="2.149ex" role="img" focusable="false" viewbox="0 -750 33400 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="merror" data-mjx-error="Unknown environment 'itemize'" title="Unknown environment 'itemize'"><rect data-background="true" width="33400" height="950" y="-200"/><title>Unknown environment 'itemize'</title><g data-mml-node="mtext" style="font-family: serif;"><text data-variant="-explicitFont" transform="scale(1,-1)" font-size="884px"> \begin{itemize} \item[$\bullet$] 文字内容 \end{itemize} </text></g></g></g></g></svg></mjx-container></span></li>
</ol>
<figure class="highlight python"><figcaption><span>feature_cutmix.py</span></figcaption><table><tr><td class="code"><pre><span class="line">x = self.layer1(x)</span><br><span class="line">bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)</span><br><span class="line">x[:,:,bbx1:bbx2,bby1:bby2] = x[rand_index,:,bbx1:bbx2,bby1:bby2]</span><br><span class="line">x = self.layer2(x)</span><br><span class="line"><span class="comment"># if you use activate fun like ReLU, change inplace=True to inplace=False</span></span><br><span class="line"><span class="number">2.</span> Mixup</span><br></pre></td></tr></table></figure>
<h2 id="xfe-psedu-label">0xFe: Psedu label</h2>
<ol start="0" type="1">
<li>Psedu label有效的一些原理上的解释
<ul>
<li>根据聚类假设（cluster
assumption），这些概率较高的点，通常在相同类别的可能性较大，所以其pseudo-label是可信度非常高的。（合理性）</li>
<li>熵正则化是在最大后验估计框架内从未标记数据中获取信息的一种方法，通过最小化未标记数据的类概率的条件熵，促进了类之间的低密度分离，而无需对密度进行任何建模，通过熵正则化与伪标签具有相同的作用效果，都是希望利用未标签数据的分布的重叠程度的信息。（有效性）</li>
<li>值得注意的是：当场景不满足 聚类假设
、熵正则化失效（样本空间覆盖密集）情况下，伪标签技术很有可能失效。</li>
<li>缺点：容易在有限的测试集上过拟合</li>
</ul></li>
<li>Psedu
label的主要思想来自于Self-Training，其实现思路是找到一种方法用未标记的数据集来扩充已标记的数据集，主要流程如下：
<ul>
<li>利用已标记的数据来训练一个好的模型，然后使用这个模型对未标记的数据进行标记</li>
<li>利用训练好的标签信息在无标签数据上进行推理，使用分数阈值（confidence
score）或其他方法从无标签数据的推理结果中过滤出可靠的标签，以选择出未标记数据的预测标签的一个子集</li>
<li>将生成的伪标签与原始的标记数据相结合，并在合并后数据上进行联合训练</li>
<li>整个过程不断重复，直到无标签数据的置信度不再上升</li>
</ul></li>
<li>伪标签往往会向模型的优化数据中混入大量噪声，使模型朝着错误的方向优化，因此需要设计一些策略解决噪声问题：
<ul>
<li>添加label smooth
，使伪标签带来的错误之心度不在sharp，从而减小错误标签导致的噪声问题 <img src="/2022/09/13/how-to-finetune/self_train_1.png" alt="selftrain"></li>
<li>打标签的过程中添加 label regularization (LR)，增加 pesudo label
的熵，类似于 label smooth 的作用</li>
<li>网络重新训练的过程中添加 model regularization
(MR)，增加网络输出概率的熵</li>
<li>使用 masked model,在模型中添加dropout，对于选出的每个 unlabeled
的数据，我们可以将其传入 N次得到不同的 T
个预测结果，直接将预测结果求平均就得到了预测标签</li>
<li>先对每个类选择相同数目的样本，防止某些类特别容易造成的样本极度不均衡。然后在每个类中使用
BALD（Bayesian Active Learning by Disagreement（BALD））
对样本进行排名并依概率抽取。如果我们想要挖掘简单样本就以 1-BALD
排名，否则以 BALD 排名，BALD有两种模式，类似数据增强 <img src="/2022/09/13/how-to-finetune/self_train_2.png" alt="self_train_2"></li>
<li>Confident
Learning：然后分别计算预测结果的均值和方差，使用模型预测的方差来对损失进行加权，目的是给与方差小的伪标注样本更大的权重</li>
</ul></li>
</ol>
<h2 id="xff-references">0xFF: References</h2>
<p>[1]: <a href="https://github.com/vandit15/Class-balanced-loss-pytorch">Class-balanced-loss-pytorch</a><br>
[2]: <a href="https://www.kaggle.com/discussions/questions-and-answers/59305">When
and why to standardize or normalize a variable?</a><br>
[3]: <a href="https://www.kaggle.com/code/rtatman/data-cleaning-challenge-scale-and-normalize-data/notebook">Data
Cleaning Challenge: Scale and Normalize Data</a><br>
[4]: <a href="https://www.kaggle.com/competitions/siim-isic-melanoma-classification/discussion/160147">CNN
Input Size Explained</a><br>
[5]: <a href="https://zhuanlan.zhihu.com/p/330333894">RankGauss</a><br>
[n-1]: <a href="https://scholar.google.com/scholar_url?url=https://www.kaggle.com/blobs/download/forum-message-attachment-files/746/pseudo_label_final.pdf&amp;hl=zh-CN&amp;sa=T&amp;oi=gsb-gga&amp;ct=res&amp;cd=0&amp;d=16547318329102522555&amp;ei=8GAoY57_CLaQ6rQP-NO84AU&amp;scisig=AAGBfm00HNXM--PNcdJRi04oq0tThe466g">Pseudo-Label
: The Simple and Efficient Semi-Supervised Learning Method for Deep
Neural Networks</a> [n]: <a href="https://helicqin.github.io/2021/03/18/Self-Training%E7%BB%BC%E8%BF%B0/">Self
Training</a></p>
]]></content>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>reveal-md</title>
    <url>/2022/05/17/reveal-md/</url>
    <content><![CDATA[<p><em>Reveal-md</em>经常用于组会汇报和一些非正式场景的PPT实现中，生成的PPT或是展示用结果由markdown组成，并且具有默认的布局样式和一些功能丰富的插件，大大简化了生成汇报用PPT的工作量。</p>
<p>其主要格式控制由两部分组成，一部分是构成其内容主体的markdown文件，另一部分是控制页面布局的css文件（一般不需要修改）。其渲染引擎使用的是<em>reveal.js</em>，通常情况下不需要对<em>reveal.js</em>进行修改（甚至基本的配置都不需要更改）。创作PPT的过程简化为了专注于内容，构建讲述逻辑，简而言之就是填充需要的内容即可。这里不过多介绍，可<a href="https://github.com/webpro/reveal-md">参考这里</a>了解更多。这篇笔记的主要内容是对一些疑难问题的记录。</p>
<ol type="1">
<li>样式控制
<strong>Reveal-md</strong>中的全局样式需要在命令行中指定样式文件和使用的主题，样式文件需要指定其具体位置，运行时可以使用
<strong>--css</strong> 和 <strong>--theme</strong>
指定。<strong>-w</strong> 表示监听文件变化，并随时刷新内容。
<figure class="highlight bash"><figcaption><span>run_file</span></figcaption><table><tr><td class="code"><pre><span class="line">reveal-md ppt.md -w --theme simple --css styles/base.css</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>字体控制
通常情况下，PPT中的中文字体使用<font face="Microsoft Yahei"><strong>微软雅黑</strong></font>，英文字体使用<font face="Times New Roman"><strong>Times
NewRoman</strong></font>,
在<strong>Reveal-md</strong>中，字体样式可以由全局的样式文件控制，这里只给出一些基本的样式定义。通过对html中所有元素的字体进行设置，可以得到全局的样式文件，同时，由于添加了
<strong>!important</strong>，其样式不会被后续的设置覆盖。同样这种方式可以设置PPT中的默认字体大小。<strong>reveal-md</strong>中的默认字体对我来说有点太大了。
<figure class="highlight css"><figcaption><span>style/style.css</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">html</span> * {</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">"Times New Roman"</span>, Times, <span class="string">"Microsoft Yahei"</span> <span class="meta">!important</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></li>
</ul>
<p>reveal 中预定义了几种字体大小，可以根据实际需求进行修改</p>
<figure class="highlight html"><figcaption><span>ppt.md</span></figcaption><table><tr><td class="code"><pre><span class="line">font-size:medium|xx-small|x-small|small|large|x-large|xx-large|smaller|larger|length|initial|inherit;</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>图像或内容居中设置
这里有两种方式，一种是全局的图像或者文字进行样式设置进行居中，另一种是创建独立的div块，对块中的内容进行居中，这里使用css优先级可以对其中的元素进行单独更新，首先在全局文件中默认左对齐，之后根据实际需求在markdown文件中再对需要的部分进行修改即可。在<strong>Reveal-md</strong>中，单独的文字或段落会被渲染成
<p>
</p>
标签的形式，因此只需要对其样式进行修改即可。 <figure class="highlight css"><figcaption><span>style/style.css</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">p</span><span class="selector-class">.left</span> {</span><br><span class="line">    <span class="attribute">text-align</span>: left;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure>
关于其他元素的居中设置，可以设置一个居中的div块，对块中的内容进行居中即可。实现方式如下：
<figure class="highlight css"><figcaption><span>style/style.css</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.center-div</span> {</span><br><span class="line">    <span class="attribute">text-align</span>: center;</span><br><span class="line">    <span class="comment">/*让div内部文字居中*/</span></span><br><span class="line">    <span class="attribute">width</span>: <span class="number">700px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">margin</span>: auto;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <tags>
        <tag>ppt</tag>
      </tags>
  </entry>
  <entry>
    <title>linux</title>
    <url>/2022/05/12/linux/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>mmdetection</title>
    <url>/2022/05/12/mmdetection/</url>
    <content><![CDATA[<p>总结一些mmdetection 中常用代码及学习技巧</p>
<ol type="1">
<li>外部引用保持代码结构整洁</li>
</ol>
<p>在mmdetection中的config可以直接引用自定义文件夹中的代码，因此可以做到代码重用，保持目录的整洁。当前github上复用mmdetection代码开发实现的相关代码仓库中大多引用了不必要的代码，因此考虑从结构上简化。其中
<em>allow_failed_imports=False</em> 会在impoort的文件不存在的时候throw
error。</p>
<figure class="highlight python"><figcaption><span>mmdetection/config/solo.py</span></figcaption><table><tr><td class="code"><pre><span class="line">custom_imports = <span class="built_in">dict</span>(</span><br><span class="line">    imports=[</span><br><span class="line">        <span class="string">"custommd.models.detectors.single_stage_ins"</span>,</span><br><span class="line">        <span class="string">"custommd.models.detectors.solov2"</span>,</span><br><span class="line">        <span class="string">"custommd.models.solov2.mask_feat_head"</span>,</span><br><span class="line">        <span class="string">"custommd.models.solov2.solov2_head"</span>,</span><br><span class="line">    ],</span><br><span class="line">    allow_failed_imports=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>使用Wandb监控实验</li>
</ol>
<p>mmdetection框架中的wandb日志实现策略在<a href="https://github.com/open-mmlab/mmcv/blob/83df7c4b00197b40c3debdb7f388a256640e13b4/mmcv/runner/hooks/logger/wandb.py">github</a>中能够找到,关于wandb的初始化参数可以参考<a href="https://docs.wandb.ai/ref/python/init">这里</a>,
配置文件中可以在<em>wandb_init_kwargs</em>中定义wandb的初始化参数。
<figure class="highlight python"><figcaption><span>mmdetection/config/model_config.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">log_config = <span class="built_in">dict</span>(</span><br><span class="line">            interval=<span class="number">10</span>,</span><br><span class="line">            hooks=[</span><br><span class="line">                <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'WandbLogger'</span>,</span><br><span class="line">                     wandb_init_kwargs={</span><br><span class="line">                         <span class="string">'entity'</span>: WANDB_ENTITY,</span><br><span class="line">                         <span class="string">'project'</span>: WANDB_PROJECT_NAME</span><br><span class="line">                     },</span><br><span class="line">                     logging_interval=<span class="number">10</span>,</span><br><span class="line">                     log_checkpoint=<span class="literal">True</span>,</span><br><span class="line">                     log_checkpoint_metadata=<span class="literal">True</span>,</span><br><span class="line">                     num_eval_images=<span class="number">100</span>)</span><br><span class="line">            ])</span><br></pre></td></tr></table></figure></p>
<ol start="3" type="1">
<li>使用timm中预训练的backbone</li>
</ol>
<p>mmdetection
中可以使用部分timm模型作为特征提取器，但是使用有所限制。使用timm库中的特征提取器需要指定使用的backbone类型。TIMMBackbone类型的具体定义在<em>mmcls.models</em>中。有两种方式可以实现，第一种是安装mmcls包后，使用其对TIMMBackbone的定义方式，显示的在config中的backbone部分制定，另一部分则是将<a href="https://raw.githubusercontent.com/open-mmlab/mmclassification/master/mmcls/models/backbones/base_backbone.py">basebackbone.py</a>文件和<a href="https://github.com/open-mmlab/mmclassification/blob/master/mmcls/models/backbones/timm_backbone.py">timm_backbone.py</a>稍作修改，主要是对其中的get_root_logger()函数修改为修改为<code>from mmdet.utils import get_root_logger</code>,通过这两种引用方式可以实现在mmdetection中使用timm库中的预训练模型。默认情况下不使用预训练的权重，需要显式指定。支持更改权重所在的位置，可以使用在image21-k上预训练的模型权重。具体代码如下：</p>
<figure class="highlight python"><figcaption><span>mmdetection/config/model_config.py</span></figcaption><table><tr><td class="code"><pre><span class="line">custom_imports = <span class="built_in">dict</span>(imports=[<span class="string">'mmcls.models'</span>], allow_failed_imports=<span class="literal">False</span>)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">custom_imports = dict(imports=[</span></span><br><span class="line"><span class="string">    'mmdet.model.backbone.timm_backbone'</span></span><br><span class="line"><span class="string">    ], allow_failed_imports=False)</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = <span class="built_in">dict</span>(</span><br><span class="line">    backbone=<span class="built_in">dict</span>(</span><br><span class="line">        _delete_=<span class="literal">True</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">'mmcls.TIMMBackbone'</span>,</span><br><span class="line">        model_name=<span class="string">'tv_resnet50'</span>,  <span class="comment"># ResNet-50 with torchvision weights</span></span><br><span class="line">        features_only=<span class="literal">True</span>,</span><br><span class="line">        pretrained=<span class="literal">True</span>,</span><br><span class="line">        checkpoint_path=<span class="string">''</span>,</span><br><span class="line">        out_indices=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)))</span><br></pre></td></tr></table></figure>
<ol start="4" type="1">
<li><p>自定义<strong>Pipeline</strong>
mmdetection中Pipeline决定了数据加载到送入模型前的数据处理过程，同时，Pipeline本身具有一定的灵活性，这里推荐结合
<a href="https://github.com/albumentations-team/albumentations">albumentations</a>
进行数据预处理，包含对bbox
的处理过程，保证增强后的图片和标签的一致性。各种增强方法图像变换前后的对比可以<a href="https://albumentations-demo.herokuapp.com/">参考这里</a>
<figure class="highlight python"><figcaption><span>mmdetection/custom_models/albumentations.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> mmcls.datasets <span class="keyword">import</span> PIPELINES</span><br><span class="line"><span class="keyword">import</span> albumentations <span class="keyword">as</span> A</span><br><span class="line"></span><br><span class="line"><span class="meta">@PIPELINES.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RandomAlbumentationsV2</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, p=<span class="number">0.6</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.p = p</span><br><span class="line">        self.transform = A.Compose([</span><br><span class="line">            A.RandomGridShuffle(always_apply=<span class="literal">False</span>, p=self.p, grid=(<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">            A.CoarseDropout(</span><br><span class="line">                always_apply=<span class="literal">False</span>, p=<span class="number">1</span>,</span><br><span class="line">                max_holes=<span class="number">16</span>,</span><br><span class="line">                max_height=<span class="number">8</span>,</span><br><span class="line">                max_width=<span class="number">8</span>,</span><br><span class="line">            ),</span><br><span class="line">            A.Downscale(</span><br><span class="line">                always_apply=<span class="literal">False</span>, p=self.p,</span><br><span class="line">                scale_min=<span class="number">0.25</span>, scale_max=<span class="number">0.25</span>, interpolation=<span class="number">0</span></span><br><span class="line">            ),</span><br><span class="line"></span><br><span class="line">            A.ISONoise(</span><br><span class="line">                always_apply=<span class="literal">False</span>, p=<span class="number">0.9</span>,</span><br><span class="line">                intensity=(<span class="number">0.0</span>, <span class="number">0.5</span>),</span><br><span class="line">                color_shift=(<span class="number">0.0</span>, <span class="number">0.5</span>),</span><br><span class="line">            ),</span><br><span class="line">             A.JpegCompression(</span><br><span class="line">                always_apply=<span class="literal">False</span>, p=self.p,</span><br><span class="line">                quality_lower=<span class="number">80</span>,</span><br><span class="line">                quality_upper=<span class="number">100</span></span><br><span class="line">            ),</span><br><span class="line">            A.MotionBlur(</span><br><span class="line">                always_apply=<span class="literal">False</span>, p=self.p, </span><br><span class="line">                blur_limit=(<span class="number">3</span>, <span class="number">10</span>),</span><br><span class="line">            ),</span><br><span class="line">            A.MultiplicativeNoise(</span><br><span class="line">                always_apply=<span class="literal">False</span>, p=<span class="number">1.0</span>, multiplier=(<span class="number">0.1</span>, <span class="number">2.0</span>),</span><br><span class="line">                per_channel=<span class="literal">True</span>,</span><br><span class="line">                elementwise=<span class="literal">True</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        ])</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, results</span>):</span><br><span class="line">        img = results[<span class="string">'img'</span>]</span><br><span class="line">        transformed = self.transform(image=img)</span><br><span class="line">        results[<span class="string">'img'</span>] = transformed[<span class="string">"image"</span>]</span><br><span class="line">        <span class="keyword">return</span> results</span><br><span class="line"></span><br></pre></td></tr></table></figure> Pipeline
定义完成后，在config相应数据处理config片段中加入定义好的预处理方法即可
<figure class="highlight python"><figcaption><span>mmdetection/config/custom_config.py</span></figcaption><table><tr><td class="code"><pre><span class="line">train_pipeline = [</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'LoadImageFromFile'</span>),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'Resize'</span>,size=<span class="number">224</span>),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'RandomAlbumentationsV2'</span>), <span class="comment"># 这里为自定义pipeline的名称，可在dict内添加对应的参数</span></span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'RandomNoise'</span>),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'RandomFlip'</span>),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'Normalize'</span>, **img_norm_cfg),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'ImageToTensor'</span>, keys=[<span class="string">'img'</span>]),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'ToTensor'</span>, keys=[<span class="string">'gt_label'</span>]),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'Collect'</span>, keys=[<span class="string">'img'</span>, <span class="string">'gt_label'</span>])</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
检查Pipeline是否正确，这里可以使用mmdetection自带的工具对pipeline处理后的图像进行可视化处理。
<figure class="highlight bash"><figcaption><span>mmdetection/show_pipeline.sh</span></figcaption><table><tr><td class="code"><pre><span class="line">python tools/visualizations/vis_pipeline.py [config_path] --output-dir [out_dir_path] --number 20 --mode concat</span><br></pre></td></tr></table></figure></p></li>
<li><p>自动保存最好的ckpt文件 mmdetection中在evaluation
epoch中可按照相应的结果保存相应指标最好的权重文件，且可设置训练多少epoch时开始保存。其自带的权重保存机制支持限制保存文件的最大数量。对应代码如下：
<figure class="highlight python"><figcaption><span>mmdetection/config/custom_config.py</span></figcaption><table><tr><td class="code"><pre><span class="line">checkpoint_config = <span class="built_in">dict</span>(interval=<span class="number">50</span>, max_keep_ckpts=<span class="number">2</span>) <span class="comment"># 每50 epoch 保存一次，保存目录中最多存在两个权重文件，evaluation生成文件不包含在限制内</span></span><br><span class="line">evaluation = <span class="built_in">dict</span>(       <span class="comment"># evaluation hook 的配置</span></span><br><span class="line">    interval=<span class="number">4</span>,          <span class="comment"># 验证期间的间隔，单位为 epoch 或者 iter， 取决于 runner 类型。</span></span><br><span class="line">    metric=<span class="string">'accuracy'</span>,</span><br><span class="line">    save_best=<span class="string">'auto'</span>,</span><br><span class="line">    start=<span class="number">50</span></span><br><span class="line">    )   <span class="comment"># 验证期间使用的指标。</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>梯度累计 训练真实使用的batchsize为 samples_per_gpu *
cumulative_iters，此项设置会影响模型训练的流程，最好不使用。
<figure class="highlight python"><figcaption><span>mmdetection/config/custom_config.py</span></figcaption><table><tr><td class="code"><pre><span class="line">optimizer_config = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">"GradientCumulativeOptimizerHook"</span>, <span class="comment"># 累积倍数</span></span><br><span class="line">    cumulative_iters=<span class="number">4</span>,</span><br><span class="line">)</span><br><span class="line">data =<span class="built_in">dict</span>(</span><br><span class="line">    samples_per_gpu=<span class="number">64</span>, <span class="comment"># 基础batchsize</span></span><br><span class="line">）</span><br></pre></td></tr></table></figure></p></li>
<li><p>学习率调节和可视化
mmdetection中有几种内置的学习速率调节策略，基本通用型为使用CosineAnnealing且随epoch不断变化的学习速率设置。如下代码，target_ratio决定了最大和最小两次的学习率倍数，这里设置学习率随着epoch不断变化。
<figure class="highlight python"><figcaption><span>mmdetection/config/custom_config.py</span></figcaption><table><tr><td class="code"><pre><span class="line">lr_config = <span class="built_in">dict</span>(</span><br><span class="line">    policy=<span class="string">'cyclic'</span>,</span><br><span class="line">    target_ratio= (<span class="number">2e3</span>, <span class="number">1e-2</span>), <span class="comment"># 决定了最大学习率倍数，实际最大值为 target_ratio[0] * lr</span></span><br><span class="line">    cyclic_times= <span class="number">5</span>, <span class="comment"># 训练开始到训练结束共调整五次</span></span><br><span class="line">    step_ratio_up= <span class="number">0.4</span>, <span class="comment"># real lr = warmup_ratio * initial lr</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">optimizer = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">'AdamW'</span>,</span><br><span class="line">    lr=<span class="number">5e-4</span> * <span class="number">128</span> * <span class="number">4</span> / <span class="number">512</span> * <span class="number">1e-4</span>, <span class="comment"># 决定了 baselr</span></span><br><span class="line">    weight_decay=<span class="number">0.0001</span>,</span><br><span class="line">    eps=<span class="number">1e-8</span>,</span><br><span class="line">    betas=(<span class="number">0.9</span>, <span class="number">0.999</span>),)</span><br></pre></td></tr></table></figure>
mmdetection中自带学习率可视化工具，可以根据config文件对学习率可视化，方便调整。
<figure class="highlight bash"><figcaption><span>mmdetection/show_lr.sh</span></figcaption><table><tr><td class="code"><pre><span class="line">python tools/visualizations/vis_lr.py [config_path] --save-path [output_path]</span><br></pre></td></tr></table></figure></p></li>
<li><p>Mixup &amp; CutPaste mmcls中支持两个比较特殊的数据增强策略，Mixup
和 CutPaste,通常结合 LabelSmoothLoss。 <figure class="highlight python"><figcaption><span>mmdetection/config/resnet.py</span></figcaption><table><tr><td class="code"><pre><span class="line">model = <span class="built_in">dict</span>(</span><br><span class="line">    backbone = ...,</span><br><span class="line">    neck = ...,</span><br><span class="line">    head = ...,</span><br><span class="line">    train_cfg=<span class="built_in">dict</span>(augments=[</span><br><span class="line">        <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'BatchMixup'</span>, alpha=<span class="number">0.8</span>, prob=<span class="number">0.5</span>, num_classes=num_classes),</span><br><span class="line">        <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'BatchCutMix'</span>, alpha=<span class="number">1.0</span>, prob=<span class="number">0.5</span>, num_classes=num_classes),</span><br><span class="line">    ]))</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p></li>
<li><p>多卡 batch norm同步设置 有两种可用的batch norm sync
设置，MMSyncBN和SyncBN,MMSyncBN为实验功能，缺少相关文档介绍。
<figure class="highlight python"><figcaption><span>mmdetection/config/base.py</span></figcaption><table><tr><td class="code"><pre><span class="line">norm_cfg=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'MMSyncBN'</span>, requires_grad=<span class="literal">True</span>) <span class="comment"># or type='SyncBN'</span></span><br></pre></td></tr></table></figure></p></li>
</ol>
]]></content>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
</search>
