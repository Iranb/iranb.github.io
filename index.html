<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"iranb.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.11.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Road to Stain‘s Gate">
<meta property="og:url" content="https://iranb.github.io/index.html">
<meta property="og:site_name" content="Road to Stain‘s Gate">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="YiQing Hao">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://iranb.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Road to Stain‘s Gate</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Road to Stain‘s Gate</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">YiQing Hao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">6</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://iranb.github.io/2022/09/26/CPP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="YiQing Hao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/09/26/CPP/" class="post-title-link" itemprop="url">C++ Guide</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-09-26 21:46:20" itemprop="dateCreated datePublished" datetime="2022-09-26T21:46:20+08:00">2022-09-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-09-27 14:09:33" itemprop="dateModified" datetime="2022-09-27T14:09:33+08:00">2022-09-27</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>648</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ol type="1">
<li>CMakeLists.txt 包含<strong>CMak</strong>命令
<ul>
<li>minimum version
<code>cmake_minimum_required(VERSION 3.5)</code></li>
<li>指定项目名称 <code>project (hello_cmake)</code></li>
<li>指定输出二进制文件对应的c++文件<code>add_executable(hello_cmake main.cpp)</code>
可以通过环境变量<code>CMAKE_BINARY_DIR</code>设置二进制文件的输出位置</li>
<li>执行<code>cmake .</code>或 <code>cmake ..</code>
命令会自动寻找路径下的CmakeLists.txt 文件，并执行其中的内容</li>
<li>执行 <code>make</code>
可以输出二进制文件，且可以指定参数如<code>make VERBOSE=1</code>会进入debug模式，终端会输出更多细节。</li>
<li>引入外部的 include 文件夹,
<ul>
<li><em>PRIVATE</em>
表示文件夹会被加入到targets对应的include文件夹下</li>
<li><em>INTERFACE</em> 表示目录会被添加到任意引用这个文件的include
文件夹内部</li>
<li><em>PUBLIC</em>
会同时包括<em>PRIVATE</em>和<em>INTERFACE</em>的功能，同时任意的target也可以链接到这个库内
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">target_include_directories(target</span><br><span class="line">    PRIVATE</span><br><span class="line">        ${PROJECT_SOURCE_DIR}/include</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><code>.a</code>文件表示静态库文件，由以下函数生成</li>
</ul></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">add_library(hello_library STATIC</span><br><span class="line">    src/Hello.cpp</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="xff-reference">0XFF Reference</h2>
<p>【1】https://github.com/ttroy50/cmake-examples</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://iranb.github.io/2022/09/13/kaggle-top-player-notes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="YiQing Hao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/09/13/kaggle-top-player-notes/" class="post-title-link" itemprop="url">kaggle top player notes</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-09-13 11:24:10 / Modified: 13:22:47" itemprop="dateCreated datePublished" datetime="2022-09-13T11:24:10+08:00">2022-09-13</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>705</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>记录一些kaggle top player 的笔记 ## <a target="_blank" rel="noopener" href="https://www.kaggle.com/christofhenkel">Dieter</a>: Deep Learning
Data Scientist at Nvidia 1. Ensemble, bag of models Dieter
使用了7个模型，集合albumentations的图像放缩 - 2x seresnext101 -
SmallMaxSize(512) -&gt; RandomCrop(448,448) - 1x seresnext101 -
Resize(686,686) -&gt; RandomCrop(568,568) - 1x b3 - LongestMaxSize(512)
-&gt; PadIfNeeded -&gt; RandomCrop(448,448) - 1x b3 -
LongestMaxSize(664) -&gt; PadIfNeeded -&gt; RandomCrop(600,600) - 1x
resnet152 - Resize(544,672) -&gt; RandomCrop(512,512) - 1x res2net101 -
Resize(544,672) -&gt; RandomCrop(512,512) 2. 使用imagenet dataset的 mean
和 std 正则化输入图像 3. 使用了GeM pooling GeM pooling
中包含一个网络参数p，随着学习过程使得网络自适应学习选择偏重平均池化或是最大池化，p=1时gem为平均池化,
<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="8.68ex" height="1.758ex" role="img" focusable="false" viewbox="0 -583 3836.6 777"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></g><g data-mml-node="mo" transform="translate(780.8,0)"><path data-c="2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"/></g><g data-mml-node="mo" transform="translate(2058.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"/></g><g data-mml-node="mi" transform="translate(2836.6,0)"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"/></g></g></g></svg></mjx-container></span>
时为最大池化，P越大越关注局部越小越关注全局 -
最大池化更多的保留的纹理特征，局部特征。 -
平均池化更多保留的背景信息，全局特征。 4. 学习率： warmup + cosine
annealing scheduler</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://iranb.github.io/2022/09/13/how-to-finetune/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="YiQing Hao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/09/13/how-to-finetune/" class="post-title-link" itemprop="url">How to finetune</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-09-13 10:14:20" itemprop="dateCreated datePublished" datetime="2022-09-13T10:14:20+08:00">2022-09-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-10-15 15:17:38" itemprop="dateModified" datetime="2022-10-15T15:17:38+08:00">2022-10-15</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>7.4k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>7 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>总结一些深度模型常用的调试优化技巧。</p>
<h2 id="x01-探索性数据分析-edaexploratory-data-analysis">0x01
探索性数据分析 EDA(Exploratory Data Analysis)</h2>
<p>探索性数据分析(EDA)是通过总结数据集的主要特征来理解数据集，进行数据清洗、为后期的参数设置提供依据。不同任务的EDA流程不同。
1. 数据分布分析
主要判断训练数据中存在的各类数据与其样本占训练数据占比，通常存在两种分布：均匀分布和长尾分布
<img src="/2022/09/13/how-to-finetune/data_dis.png">
类别分布不均衡的数据集（不一定呈现长尾分布）需要设置策略如Inbalcance
loss 、 Data expansion减少对结果的影响。 <img src="/2022/09/13/how-to-finetune/coco_eda.png"> 2.
超参数设置分析
在检测模型中，通常会用到预先设计的anchor，anchor的设计尺寸与目标在图像中的位置、大小以及深度网络的不同层尺寸、深度有关。
<img src="/2022/09/13/how-to-finetune/anchor.png"><br>
<img src="/2022/09/13/how-to-finetune/coco_eda2.png"> 3. 输入图像的size 设置
之后会介绍不同输入图像尺寸对深度模型拟合的影响。 4. Noisy data &amp; OOD
data
包含数据缺失、标注缺失、错误标注、异常等数据种类，一般在公开数据集中存在较少。</p>
<h2 id="x02-正则化">0x02 正则化</h2>
<ol type="1">
<li>常用方法
<ul>
<li>Z score Normalization（mean std Standardization）</li>
</ul></li>
</ol>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.577ex;" xmlns="http://www.w3.org/2000/svg" width="6.349ex" height="4.824ex" role="img" focusable="false" viewbox="0 -1435 2806.4 2132"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(794.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/></g><g data-mml-node="mover" transform="translate(1794.4,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(0,374)"><svg width="572" height="237" x="0" y="148" viewbox="143 148 572 237"><path data-c="2013" d="M0 248V285H499V248H0Z" transform="scale(1.716,1)"/></svg></g></g></g><g data-mml-node="mi" transform="translate(1117.7,-686)"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"/></g><rect width="2566.4" height="60" x="120" y="220"/></g></g></g></svg></mjx-container></span></p>
<pre><code>- Min-Max Scaling
- Standard Deviation Method
- Range Method
- RankGauss(top1-recon)
通常RankGauss的效果也会比标准化和归一化好</code></pre>
<figure class="highlight python"><figcaption><span>mmdetection/rankgauss</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> erfinv</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scale_minmax</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="string">'''归一化'''</span></span><br><span class="line">    <span class="keyword">return</span> (x - x.<span class="built_in">min</span>()) / (x.<span class="built_in">max</span>() - x.<span class="built_in">min</span>())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scale_norm</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="string">'''标准化'''</span></span><br><span class="line">    <span class="keyword">return</span> (x - x.mean()) / x.std()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scale_rankgauss</span>(<span class="params">x, epsilon=<span class="number">1e-6</span></span>):</span><br><span class="line">    <span class="string">'''rankgauss'''</span></span><br><span class="line">    x = x.argsort().argsort() <span class="comment"># rank</span></span><br><span class="line">    x = (x/x.<span class="built_in">max</span>()-<span class="number">0.5</span>)*<span class="number">2</span> <span class="comment"># scale</span></span><br><span class="line">    x = np.clip(x, -<span class="number">1</span>+epsilon, <span class="number">1</span>-epsilon)</span><br><span class="line">    x = erfinv(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>RankGauss基于秩变换，第一步是为从-1到1排序的特征分配一个线性空间，然后应用误差函数ErfInv的逆函数使输入数据分布转化为高斯函数，然后减去平均值。</p>
<ol start="2" type="1">
<li>为什么需要使用正则化方法
<ul>
<li>For Cluster
Analysis：通常情况需要度量不同输入间的距离，未正则化数据可能会存在特殊极值影响度量结果。</li>
<li>For Principal Component Analysis：PCA gives more weightage to those
variables that have higher variances than to those variables that have
very low variances（方差会影响降维结果）</li>
<li>正则化能改变输入数据的分布，在数据预处理时通常包含两个步骤：Scaling
&amp; Normalize， Scaling负责将输入数据映射到0-1范围内，Scaling can help
compare different variables on equal
footing（在同样的步长上比较两个数据）;
Normalization本质上是一种激进的策略，The point of normalization is to
change your observations so that they can be described as a normal
distribution.Normalization能够改变模型观察数据的角度，使输入数据可以被描述为一个正态分布。</li>
<li>Scaling(归一化)消除特征间单位和尺度差异的影响，以对每维特征同等看待，需要对特征进行归一化。</li>
<li>因尺度差异，其损失函数的等高线图可能是椭圆形，梯度方向垂直于等高线,变换后，其损失函数的等高线图更接近圆形，梯度下降的方向震荡更小，收敛更快</li>
<li>随着训练程度加深，模型复杂度会增加，偏差减少，方差增大，而泛化误差呈现
U
型变化，对于一个“好的系统”通常要求误差小，正则化的作用即为适当的控制模型复杂度，从而使得泛化误差曲线取最小值<img src="/2022/09/13/how-to-finetune/normlize.png" alt="如图">，从贝叶斯角度考虑，正则项等价于引入参数的模型先验概率，可以简单理解为对最大似然估计（MLE）引入先验概率，从而转化为最大后验估计（MAP），其中的先验概率即对于正则项</li>
</ul></li>
</ol>
<h2 id="x03-输入图像的尺寸对网络的影响">0x03:
输入图像的尺寸对网络的影响</h2>
<ol type="1">
<li>ImageNet
上预训练的backbone模型通常在224x224大小的输入图像上进行预训练，这并不意味着我们需要将输入图像resize到224x224大小</li>
<li>以224x224大小的输入数据为例，假设输入图像经过网络输出的特征图大小为原始图像的<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.816ex;" xmlns="http://www.w3.org/2000/svg" width="2.595ex" height="2.773ex" role="img" focusable="false" viewbox="0 -864.9 1147.1 1225.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mn" transform="translate(396.8,394) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="mn" transform="translate(220,-345) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"/><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"/></g><rect width="907.1" height="60" x="120" y="220"/></g></g></g></svg></mjx-container></span>,如果将输入图像尺寸增大到512x512,则对应的输出特征图大小从7x7变为16x16，特征图的输出大小仅与网络本身结构和输入的图像大小有关。</li>
<li>在模型中，与预训练尺寸有关的是网络从确定大小物体中学习到的固定模式，例如从输入图像中寻找直径为50个像素大小的圆，或是边长为30个像素的三角形。以下三个图为例
<img src="/2022/09/13/how-to-finetune/FLower.png" alt="FLower"> <img src="/2022/09/13/how-to-finetune/car.png" alt="car">
<img src="/2022/09/13/how-to-finetune/dogs.png" alt="Dogs"></li>
<li>假设将输入图像大小放大到512x512会发生什么：放缩输入图像的大小等价于放缩图像中的物体，CNN可能找不到直径50的圆和边长30的三角形。
<img src="/2022/09/13/how-to-finetune/result_512.jpg" alt="result_512">
如果图像尺寸缩小到128，模型可能找不到其中的圆 <img src="/2022/09/13/how-to-finetune/result_128.jpg" alt="result_128"></li>
<li>结论
CNN能从图像中搜索固定的模式（patterns），这些固定的模式可能和图像的尺寸相关，因此需要通过实验寻找不同模式对应的input
size， 或者融合多尺度特征。</li>
</ol>
<h2 id="x04-dataaugmentation">0x04 DataAugmentation</h2>
<ol start="0" type="1">
<li><p>Mosaic 数据增强方法
数据增强的目的是在有限的训练数据基础上构建更多的可训练样本，同时缩小训练集和测试集的数据gap；这里主要介绍基于Mosaic的数据增强方法，最早在YOLOV4的论文中提及，主要思想是将多张图片进行随机裁剪，再拼接到一张图上作为训练数据。这样做的好处是丰富了图片的背景，变相增大了batch
size 而且不增加额外的计算量。 <img src="/2022/09/13/how-to-finetune/mosaic.png" alt="mosaic"></p></li>
<li><p>Mixup ICLR 2018<br>
基本思想是按照一定的全局比例叠加图像，能更好的将两个易混淆的类别区分，增大类间距。对应的公式如下所示：
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.136ex;" xmlns="http://www.w3.org/2000/svg" width="19.547ex" height="5.404ex" role="img" focusable="false" viewbox="0 -1444.2 8639.7 2388.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtable"><g data-mml-node="mtr" transform="translate(0,694.2)"><g data-mml-node="mtd"/><g data-mml-node="mtd"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(313.8,332) translate(-250 0)"><path data-c="7E" d="M179 251Q164 251 151 245T131 234T111 215L97 227L83 238Q83 239 95 253T121 283T142 304Q165 318 187 318T253 300T320 282Q335 282 348 288T368 299T388 318L402 306L416 295Q375 236 344 222Q330 215 313 215Q292 215 248 233T179 251Z"/></g></g></g><g data-mml-node="mo" transform="translate(849.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mi" transform="translate(1905.6,0)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="msub" transform="translate(2488.6,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g><g data-mml-node="mo" transform="translate(3609.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"/></g><g data-mml-node="mo" transform="translate(4610,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mn" transform="translate(4999,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="mo" transform="translate(5721.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/></g><g data-mml-node="mi" transform="translate(6721.4,0)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="mo" transform="translate(7304.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="msub" transform="translate(7693.4,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"/></g></g></g></g><g data-mml-node="mtr" transform="translate(0,-650)"><g data-mml-node="mtd"/><g data-mml-node="mtd"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mo" transform="translate(300.6,332) translate(-250 0)"><path data-c="7E" d="M179 251Q164 251 151 245T131 234T111 215L97 227L83 238Q83 239 95 253T121 283T142 304Q165 318 187 318T253 300T320 282Q335 282 348 288T368 299T388 318L402 306L416 295Q375 236 344 222Q330 215 313 215Q292 215 248 233T179 251Z"/></g></g></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mi" transform="translate(1823.6,0)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="msub" transform="translate(2406.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/></g></g><g data-mml-node="mo" transform="translate(3445.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"/></g><g data-mml-node="mo" transform="translate(4446,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mn" transform="translate(4835,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="mo" transform="translate(5557.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/></g><g data-mml-node="mi" transform="translate(6557.4,0)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="mo" transform="translate(7140.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="msub" transform="translate(7529.4,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"/></g></g></g></g></g></g></g></svg></mjx-container></span> mixup原文中，证明能够很好区分两个类的依据实验： <img src="/2022/09/13/how-to-finetune/mixup.png" alt="mixup">
mixup适用于有监督的任务中，通常用于区分易混淆类，也有增大 训练batch size
的功能。</p></li>
<li><p>CutMix ICCV 2019<br>
将不同类别图片的输入或特征剪切，并合并到一张图内，作为新的输入,CutMix对应的公式如下:
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.036ex;" xmlns="http://www.w3.org/2000/svg" width="28.754ex" height="5.204ex" role="img" focusable="false" viewbox="0 -1400 12709.4 2300"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtable"><g data-mml-node="mtr" transform="translate(0,650)"><g data-mml-node="mtd"/><g data-mml-node="mtd"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(313.8,332) translate(-250 0)"><path data-c="7E" d="M179 251Q164 251 151 245T131 234T111 215L97 227L83 238Q83 239 95 253T121 283T142 304Q165 318 187 318T253 300T320 282Q335 282 348 288T368 299T388 318L402 306L416 295Q375 236 344 222Q330 215 313 215Q292 215 248 233T179 251Z"/></g></g></g><g data-mml-node="mo" transform="translate(849.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(1905.6,0)"><g data-mml-node="mi"><path data-c="1D40C" d="M314 0Q296 3 181 3T48 0H39V62H147V624H39V686H305Q316 679 323 667Q330 653 434 414L546 157L658 414Q766 662 773 674Q778 681 788 686H1052V624H944V62H1052V0H1040Q1016 3 874 3T708 0H696V62H804V341L803 618L786 580Q770 543 735 462T671 315Q540 13 536 9Q528 1 507 1Q485 1 477 9Q472 14 408 162T281 457T217 603Q215 603 215 334V62H323V0H314Z"/></g></g><g data-mml-node="mo" transform="translate(3219.8,0)"><path data-c="2299" d="M56 250Q56 394 156 488T384 583Q530 583 626 485T722 250Q722 110 625 14T390 -83Q249 -83 153 14T56 250ZM682 250Q682 322 649 387T546 497T381 542Q272 542 184 459T95 250Q95 132 178 45T389 -42Q515 -42 598 45T682 250ZM311 250Q311 285 332 304T375 328Q376 328 382 328T392 329Q424 326 445 305T466 250Q466 217 445 195T389 172Q354 172 333 195T311 250Z"/></g><g data-mml-node="msub" transform="translate(4220,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mi" transform="translate(605,-152.7) scale(0.707)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g></g><g data-mml-node="mo" transform="translate(5627.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"/></g><g data-mml-node="mo" transform="translate(6627.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(7016.8,0)"><g data-mml-node="mn"><path data-c="1D7CF" d="M481 0L294 3Q136 3 109 0H96V62H227V304Q227 546 225 546Q169 529 97 529H80V591H97Q231 591 308 647L319 655H333Q355 655 359 644Q361 640 361 351V62H494V0H481Z"/></g></g><g data-mml-node="mo" transform="translate(7814,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(8814.2,0)"><g data-mml-node="mi"><path data-c="1D40C" d="M314 0Q296 3 181 3T48 0H39V62H147V624H39V686H305Q316 679 323 667Q330 653 434 414L546 157L658 414Q766 662 773 674Q778 681 788 686H1052V624H944V62H1052V0H1040Q1016 3 874 3T708 0H696V62H804V341L803 618L786 580Q770 543 735 462T671 315Q540 13 536 9Q528 1 507 1Q485 1 477 9Q472 14 408 162T281 457T217 603Q215 603 215 334V62H323V0H314Z"/></g></g><g data-mml-node="mo" transform="translate(9906.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="mo" transform="translate(10517.4,0)"><path data-c="2299" d="M56 250Q56 394 156 488T384 583Q530 583 626 485T722 250Q722 110 625 14T390 -83Q249 -83 153 14T56 250ZM682 250Q682 322 649 387T546 497T381 542Q272 542 184 459T95 250Q95 132 178 45T389 -42Q515 -42 598 45T682 250ZM311 250Q311 285 332 304T375 328Q376 328 382 328T392 329Q424 326 445 305T466 250Q466 217 445 195T389 172Q354 172 333 195T311 250Z"/></g><g data-mml-node="msub" transform="translate(11517.7,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"/></g></g></g></g><g data-mml-node="mtr" transform="translate(0,-650)"><g data-mml-node="mtd"/><g data-mml-node="mtd"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mo" transform="translate(300.6,332) translate(-250 0)"><path data-c="7E" d="M179 251Q164 251 151 245T131 234T111 215L97 227L83 238Q83 239 95 253T121 283T142 304Q165 318 187 318T253 300T320 282Q335 282 348 288T368 299T388 318L402 306L416 295Q375 236 344 222Q330 215 313 215Q292 215 248 233T179 251Z"/></g></g></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/></g><g data-mml-node="mi" transform="translate(1823.6,0)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="msub" transform="translate(2406.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(523,-152.7) scale(0.707)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g></g><g data-mml-node="mo" transform="translate(3732.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"/></g><g data-mml-node="mo" transform="translate(4732.3,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"/></g><g data-mml-node="mn" transform="translate(5121.3,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="mo" transform="translate(5843.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/></g><g data-mml-node="mi" transform="translate(6843.8,0)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"/></g><g data-mml-node="mo" transform="translate(7426.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"/></g><g data-mml-node="msub" transform="translate(7815.8,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"/></g></g></g></g></g></g></g></svg></mjx-container></span></p></li>
</ol>
<p>值得注意的是，Cutmix 本身支持在特征层进行。 <figure class="highlight python"><figcaption><span>feature_cutmix.py</span></figcaption><table><tr><td class="code"><pre><span class="line">x = self.layer1(x)</span><br><span class="line">bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)</span><br><span class="line">x[:,:,bbx1:bbx2,bby1:bby2] = x[rand_index,:,bbx1:bbx2,bby1:bby2]</span><br><span class="line">x = self.layer2(x)</span><br><span class="line"><span class="comment"># if you use activate fun like ReLU, change inplace=True to inplace=False</span></span><br></pre></td></tr></table></figure>
从论文中的结果中来看，Cutmix更适合于无监督任务中。<br>
4. ImageNet性能结果<br>
基于ResNet-50的无监督和有监督分类结果</p>
<table>
<thead>
<tr class="header">
<th>测试性能 top-1</th>
<th>Cutout</th>
<th>Mixup</th>
<th>CutMix</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>有监督 ACC</td>
<td>77.07</td>
<td>77.42</td>
<td>77.6</td>
</tr>
<tr class="even">
<td>无监督 ACC</td>
<td>46.69</td>
<td>45.84</td>
<td>47.25</td>
</tr>
</tbody>
</table>
<p>相比于CutMix，
Mixup实现简单且更常用，CutMix在检测任务和其他下游任务上需要针对目标所在区域进行裁剪，因此难用一些，目前kaggle上常用Mixup区分易混淆类别。上述的增强方法必须结合带有<strong>label
smooth</strong>的loss进行训练才能保证有效。</p>
<p><del>5. 补充 ROI-crop</del>（实现困难 下策）
<del>ROI-crop是一种难以实现但效果非常好的增强方式，其思路是从图像中去除大部分背景信息，使模型更加关注目标所在区域，一般需要使用预训练的ROI网络对图像进行处理</del></p>
<ol start="5" type="1">
<li>Class balanced over sampling[7]<br>
主要是处理不平衡的数据输入，思路是通过对常见类进行少量采样、对罕见类进行过采样或二者同时进行。</li>
</ol>
<ul>
<li>Synthetic Minority Over-sampling
TEchnique(SMOTE):SMOTE算法的基本思想就是对少数类别样本进行分析和模拟，并将人工模拟的新样本添加到数据集中</li>
<li>实际使用时通过数据增强的方式模拟样本，并添加到训练样本</li>
<li>这里推荐<a target="_blank" rel="noopener" href="https://imbalanced-learn.org/stable/references/index.html#api">imbalanced-learn</a>,
实现了数据层和特征层的Under-sampling methods和Over-sampling
methods以及两种方法的整合</li>
</ul>
<h2 id="x05-training-settings">0x05 Training settings</h2>
<ol start="0" type="1">
<li>模型训练和Finetune时需要注意的点<br>
</li>
</ol>
<ul>
<li>初始调试过程使用的模型结构不要太大，便于loss、lr或超参数的调整。</li>
<li>是否使用预训练模型取决于与训练模型是否对task有帮助、例如不类别重合、场景重合</li>
<li></li>
</ul>
<ol type="1">
<li><p>损失函数设计<br>
原则：混合多种loss一定会导致训练难度增加、甚至由于优化方向不同，导致最终精度下降。最好的方法是分阶段的finetune，保证每个时刻的训练有恒定的优化方向。</p>
<ul>
<li>Inbalcanced dataset：主要处理训练数据中类别不平衡
<ul>
<li>Balanced loss：
一般思路是在不同类计算损失时，根据类别占比添加计算权重</li>
</ul></li>
<li>Hard Example：训练集中部分样本识别准确率无法提升
<ul>
<li>Online Hard Example
Mining(OHEM)：一般思路是增大loss较大样本对应的权重（认为loss较大是因为模型难以从该样本中学习到Task相关的归纳偏置。</li>
<li>算法的核心是选择一些hard
example作为训练的样本从而改善网络参数效果，hard
example指的是有多样性和高损失的样本。</li>
<li>参考<a target="_blank" rel="noopener" href="https://github.com/CoinCheung/pytorch-loss">github</a></li>
</ul></li>
<li>None Label
<ul>
<li>Self supervised loss：<a target="_blank" rel="noopener" href="https://github.com/KevinMusgrave/pytorch-metric-learning">基于对比学习的损失</a></li>
<li>通过不同的metric
在高维映射空间上对训练样本进行度量，取度量结果相近似的为一类。</li>
</ul></li>
</ul></li>
<li><p>如何使用不同的损失进行finetune</p>
<ul>
<li>step one：Task based loss pretrain</li>
<li>step two：pretrained model finetune with specific loss function</li>
<li>metric learning loss 通常用于预训练阶段，属于上游训练过程。</li>
</ul></li>
<li><p>学习率 finetune<br>
在<strong>Cyclical Learning Rates for Training Neural
Network</strong>论文中提供了详尽的介绍，理论最优的lr如下图： <img src="/2022/09/13/how-to-finetune/lr.png" alt="lr">
训练时使用的lr变化过程大致分为三个部分：</p></li>
</ol>
<ul>
<li>The initial
warm-up：通常模型的训练过程中会使用到预训练模型，warm-up可以最大程度保证与训练模型中的已有知识的同时适应新的任务</li>
<li>Cyclical adaptive
adjust：周期性的从大到小调整学习率，防止模型陷入局部最优</li>
<li>Decrease by global
step：为了保证模型能在全局最优区域中持续探索最优解
但在实际实验时，通常难以寻找合适的初始学习速率，只能通过实验进行测试,寻找对应loss下降最快（-斜率大）的lr，初始的学习速率只是为了加速模型的训练过程，而不是为了模型能取得最优精度。</li>
<li>这种策略并不适合SGD优化器，其梯度下降过程可视化为下图： <img src="/2022/09/13/how-to-finetune/gradient.png" alt="gradient"></li>
<li>如何寻找lr？Plotting a graph between the learning rate and the loss
function。 <img src="/2022/09/13/how-to-finetune/find_lr.png" alt="find_lr"></li>
</ul>
<p>finetune时，kaggle中通常使用的lr一般为模型取得最优时的lr/ratio，采用固定训练lr对模型进行调优。
adamw、Nadam等adam类optimizer可以用于模型的l<strong>low
lr</strong>微调过程，这种优化器通常对学习速率变化更敏感。
SGD在训练阶段可以让模型快速拟合，但易与于陷入局部最优（上限不高，可以用于前期模型预训练过程）</p>
<ol start="4" type="1">
<li>无测试集标签的时候，过拟合训练策略（收集自kaggle）
在没有测试集标签的情况下，判断是否过拟合主要通过训练集数据划分。</li>
</ol>
<ul>
<li>模型有后续的finetune过程，则在初始训练的时候可以过拟合</li>
<li>不清楚训练数据集噪声分布情况下，在训练过程中堆叠了大量数据增强与噪声方法，模型存在过拟合</li>
</ul>
<h2 id="x06-结果分析">0x06 结果分析</h2>
<ol type="1">
<li>Confusion matrix<br>
Confusion
matrix基于训练数据标签对预测结果分析，可以从中分析出易混淆类别（近似样本）、难样本，其实现思路为：</li>
</ol>
<ul>
<li>给定评测指标，统计网络预测与真实值间的指标差异，以分类任务为例：
<img src="/2022/09/13/how-to-finetune/confusion.png"></li>
<li>We can do more data augmentation to try to make the model learn that
class.</li>
</ul>
<ol start="2" type="1">
<li><p>特征可视化（Score-CAM CVPRW2020）
基于置信分数的视觉可解释性方法，基于特征图的线性加权得到特征图的全局置信分数，衡量线性权重。
<img src="/2022/09/13/how-to-finetune/CAM.png"></p></li>
<li><p>特征降维分析（T-SNE） <img src="/2022/09/13/how-to-finetune/tsne.png"></p></li>
</ol>
<ul>
<li>T-SNE
<ul>
<li>不足：一是处理大规模高维数据时，t-SNE的效率显著降低，
二是t-SNE中的参数对不同数据集较为敏感</li>
</ul></li>
<li>LargeVis
<ul>
<li>改进了T-SNE计算慢的缺点，同样采用T分布策略以达到一致的效果</li>
</ul></li>
</ul>
<h2 id="x07-维度变换模块">0x07 维度变换模块</h2>
<p>原始特征维度为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="11.572ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 5114.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"/></g><g data-mml-node="mi" transform="translate(278,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"/></g><g data-mml-node="msub" transform="translate(1037,0)"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"/></g><g data-mml-node="mn" transform="translate(748,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g></g><g data-mml-node="msub" transform="translate(2188.6,0)"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"/></g><g data-mml-node="mn" transform="translate(864,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g></g><g data-mml-node="msub" transform="translate(3456.1,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"/></g><g data-mml-node="mn" transform="translate(977,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g></g><g data-mml-node="mo" transform="translate(4836.7,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"/></g></g></g></svg></mjx-container></span>，变换后为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="11.572ex" height="2.262ex" role="img" focusable="false" viewbox="0 -750 5114.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"/></g><g data-mml-node="mi" transform="translate(278,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"/></g><g data-mml-node="msub" transform="translate(1037,0)"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"/></g><g data-mml-node="mn" transform="translate(748,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/></g></g><g data-mml-node="msub" transform="translate(2188.6,0)"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"/></g><g data-mml-node="mn" transform="translate(864,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/></g></g><g data-mml-node="msub" transform="translate(3456.1,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"/></g><g data-mml-node="mn" transform="translate(977,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/></g></g><g data-mml-node="mo" transform="translate(4836.7,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"/></g></g></g></svg></mjx-container></span> 1. O &gt; M</p>
<h2 id="xfe-psedu-label">0xFe: Psedu label</h2>
<ol start="0" type="1">
<li>Psedu label有效的一些原理上的解释
<ul>
<li>根据聚类假设（cluster
assumption），这些概率较高的点，通常在相同类别的可能性较大，所以其pseudo-label是可信度非常高的。（合理性）</li>
<li>熵正则化是在最大后验估计框架内从未标记数据中获取信息的一种方法，通过最小化未标记数据的类概率的条件熵，促进了类之间的低密度分离，而无需对密度进行任何建模，通过熵正则化与伪标签具有相同的作用效果，都是希望利用未标签数据的分布的重叠程度的信息。（有效性）</li>
<li>值得注意的是：当场景<strong>不满足聚类假设</strong>
、<strong>熵正则化失效（样本空间覆盖密集）</strong>情况下，伪标签技术很有可能失效。</li>
<li>缺点：容易在有限的测试集上过拟合</li>
</ul></li>
<li>Psedu
label的主要思想来自于Self-Training，其实现思路是找到一种方法用未标记的数据集来扩充已标记的数据集，主要流程如下：
<ul>
<li>利用已标记的数据来训练一个好的模型，然后使用这个模型对未标记的数据进行标记</li>
<li>利用训练好的标签信息在无标签数据上进行推理，使用分数阈值（confidence
score）或其他方法从无标签数据的推理结果中过滤出可靠的标签，以选择出未标记数据的预测标签的一个子集</li>
<li>将生成的伪标签与原始的标记数据相结合，并在合并后数据上进行联合训练</li>
<li>整个过程不断重复，直到无标签数据的置信度不再上升</li>
</ul></li>
<li>伪标签往往会向模型的优化数据中混入大量噪声，使模型朝着错误的方向优化，因此需要设计一些策略解决噪声问题：
<ul>
<li><p>添加label smooth
，使伪标签带来的错误之心度不在sharp，从而减小错误标签导致的噪声问题 <img src="/2022/09/13/how-to-finetune/self_train_1.png" alt="selftrain"></p></li>
<li><p>打标签的过程中添加 label regularization (LR)，增加 pesudo label
的熵，类似于 label smooth 的作用</p></li>
<li><p>网络重新训练的过程中添加 model regularization
(MR)，增加网络输出概率的熵</p></li>
<li><p>使用 masked model,在模型中添加dropout，对于选出的每个 unlabeled
的数据，我们可以将其传入 N次得到不同的 T
个预测结果，直接将预测结果求平均就得到了预测标签</p></li>
<li><p>先对每个类选择相同数目的样本，防止某些类特别容易造成的样本极度不均衡。然后在每个类中使用
BALD（Bayesian Active Learning by Disagreement（BALD））
对样本进行排名并依概率抽取。如果我们想要挖掘简单样本就以 1-BALD
排名，否则以 BALD 排名，BALD有两种模式，类似数据增强 <img src="/2022/09/13/how-to-finetune/self_train_2.png" alt="self_train_2"></p></li>
<li><p>Confident
Learning：然后分别计算预测结果的均值和方差，使用模型预测的方差来对损失进行加权，目的是给与方差小的伪标注样本更大的权重</p></li>
</ul></li>
</ol>
<h2 id="xnn0归纳偏置inductive-bias">0xNN0归纳偏置（inductive bias）</h2>
<ol type="1">
<li>定义</li>
</ol>
<ul>
<li>指的是学习算法中，当学习器去预测其未遇到过的输入结果时，所做的一些假设的集合</li>
<li>模型在预测训练中未出现的样本时，若无任何约束未知样本可以是对应任意的结果，若没有其它额外的假设，问题就无法解决。</li>
<li>关于目标函数的必要假设就称为归纳偏置</li>
</ul>
<ol start="2" type="1">
<li>归纳偏置种类
<ul>
<li>最大条件独立性</li>
<li>最小交叉验证误差</li>
<li>最大边界</li>
<li>最小描述长度</li>
<li>最少特征数</li>
<li>最近邻</li>
</ul></li>
<li>虽然大部分的学习算法使用固定的偏置，但有些算法在获得更多数据时可以变换它们的偏置。这不会取消偏置，因为偏置变换的过程本身就是一种偏置。</li>
</ol>
<h2 id="xff-references">0xFF: References</h2>
<p>[1]: <a target="_blank" rel="noopener" href="https://github.com/vandit15/Class-balanced-loss-pytorch">Class-balanced-loss-pytorch</a><br>
[2]: <a target="_blank" rel="noopener" href="https://www.kaggle.com/discussions/questions-and-answers/59305">When
and why to standardize or normalize a variable?</a><br>
[3]: <a target="_blank" rel="noopener" href="https://www.kaggle.com/code/rtatman/data-cleaning-challenge-scale-and-normalize-data/notebook">Data
Cleaning Challenge: Scale and Normalize Data</a><br>
[4]: <a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/siim-isic-melanoma-classification/discussion/160147">CNN
Input Size Explained</a><br>
[5]: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/330333894">RankGauss</a><br>
[6]: <a target="_blank" rel="noopener" href="https://www.jair.org/index.php/jair/article/view/10302/24590">SMOTE
重复采样</a> [7]: <a target="_blank" rel="noopener" href="https://www.kaggle.com/code/residentmario/oversampling-with-smote-and-adasyn/notebook">Oversampling
with SMOTE and ADASYN</a> [n-1]: <a target="_blank" rel="noopener" href="https://scholar.google.com/scholar_url?url=https://www.kaggle.com/blobs/download/forum-message-attachment-files/746/pseudo_label_final.pdf&amp;hl=zh-CN&amp;sa=T&amp;oi=gsb-gga&amp;ct=res&amp;cd=0&amp;d=16547318329102522555&amp;ei=8GAoY57_CLaQ6rQP-NO84AU&amp;scisig=AAGBfm00HNXM--PNcdJRi04oq0tThe466g">Pseudo-Label
: The Simple and Efficient Semi-Supervised Learning Method for Deep
Neural Networks</a><br>
[n]: <a target="_blank" rel="noopener" href="https://helicqin.github.io/2021/03/18/Self-Training%E7%BB%BC%E8%BF%B0/">Self
Training</a></p>
<p>[n+1]: <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%BD%92%E7%BA%B3%E5%81%8F%E7%BD%AE">归纳偏置
wiki</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://iranb.github.io/2022/05/17/reveal-md/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="YiQing Hao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/17/reveal-md/" class="post-title-link" itemprop="url">reveal-md</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-17 15:29:24" itemprop="dateCreated datePublished" datetime="2022-05-17T15:29:24+08:00">2022-05-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-06-09 18:00:36" itemprop="dateModified" datetime="2022-06-09T18:00:36+08:00">2022-06-09</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>1.3k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><em>Reveal-md</em>经常用于组会汇报和一些非正式场景的PPT实现中，生成的PPT或是展示用结果由markdown组成，并且具有默认的布局样式和一些功能丰富的插件，大大简化了生成汇报用PPT的工作量。</p>
<p>其主要格式控制由两部分组成，一部分是构成其内容主体的markdown文件，另一部分是控制页面布局的css文件（一般不需要修改）。其渲染引擎使用的是<em>reveal.js</em>，通常情况下不需要对<em>reveal.js</em>进行修改（甚至基本的配置都不需要更改）。创作PPT的过程简化为了专注于内容，构建讲述逻辑，简而言之就是填充需要的内容即可。这里不过多介绍，可<a target="_blank" rel="noopener" href="https://github.com/webpro/reveal-md">参考这里</a>了解更多。这篇笔记的主要内容是对一些疑难问题的记录。</p>
<ol type="1">
<li>样式控制
<strong>Reveal-md</strong>中的全局样式需要在命令行中指定样式文件和使用的主题，样式文件需要指定其具体位置，运行时可以使用
<strong>--css</strong> 和 <strong>--theme</strong>
指定。<strong>-w</strong> 表示监听文件变化，并随时刷新内容。
<figure class="highlight bash"><figcaption><span>run_file</span></figcaption><table><tr><td class="code"><pre><span class="line">reveal-md ppt.md -w --theme simple --css styles/base.css</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>字体控制
通常情况下，PPT中的中文字体使用<font face="Microsoft Yahei"><strong>微软雅黑</strong></font>，英文字体使用<font face="Times New Roman"><strong>Times
NewRoman</strong></font>,
在<strong>Reveal-md</strong>中，字体样式可以由全局的样式文件控制，这里只给出一些基本的样式定义。通过对html中所有元素的字体进行设置，可以得到全局的样式文件，同时，由于添加了
<strong>!important</strong>，其样式不会被后续的设置覆盖。同样这种方式可以设置PPT中的默认字体大小。<strong>reveal-md</strong>中的默认字体对我来说有点太大了。
<figure class="highlight css"><figcaption><span>style/style.css</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">html</span> * {</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">"Times New Roman"</span>, Times, <span class="string">"Microsoft Yahei"</span> <span class="meta">!important</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></li>
</ul>
<p>reveal 中预定义了几种字体大小，可以根据实际需求进行修改</p>
<figure class="highlight html"><figcaption><span>ppt.md</span></figcaption><table><tr><td class="code"><pre><span class="line">font-size:medium|xx-small|x-small|small|large|x-large|xx-large|smaller|larger|length|initial|inherit;</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>图像或内容居中设置
这里有两种方式，一种是全局的图像或者文字进行样式设置进行居中，另一种是创建独立的div块，对块中的内容进行居中，这里使用css优先级可以对其中的元素进行单独更新，首先在全局文件中默认左对齐，之后根据实际需求在markdown文件中再对需要的部分进行修改即可。在<strong>Reveal-md</strong>中，单独的文字或段落会被渲染成
<p>
</p>
标签的形式，因此只需要对其样式进行修改即可。 <figure class="highlight css"><figcaption><span>style/style.css</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">p</span><span class="selector-class">.left</span> {</span><br><span class="line">    <span class="attribute">text-align</span>: left;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure>
关于其他元素的居中设置，可以设置一个居中的div块，对块中的内容进行居中即可。实现方式如下：
<figure class="highlight css"><figcaption><span>style/style.css</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.center-div</span> {</span><br><span class="line">    <span class="attribute">text-align</span>: center;</span><br><span class="line">    <span class="comment">/*让div内部文字居中*/</span></span><br><span class="line">    <span class="attribute">width</span>: <span class="number">700px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">margin</span>: auto;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://iranb.github.io/2022/05/12/linux/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="YiQing Hao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/12/linux/" class="post-title-link" itemprop="url">linux</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-12 16:36:00" itemprop="dateCreated datePublished" datetime="2022-05-12T16:36:00+08:00">2022-05-12</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>0</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://iranb.github.io/2022/05/12/mmdetection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="YiQing Hao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/12/mmdetection/" class="post-title-link" itemprop="url">mmdetection</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-05-12 16:31:53" itemprop="dateCreated datePublished" datetime="2022-05-12T16:31:53+08:00">2022-05-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-09-13 11:15:36" itemprop="dateModified" datetime="2022-09-13T11:15:36+08:00">2022-09-13</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>5.5k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>5 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>总结一些mmdetection 中常用代码及学习技巧</p>
<ol type="1">
<li>外部引用保持代码结构整洁</li>
</ol>
<p>在mmdetection中的config可以直接引用自定义文件夹中的代码，因此可以做到代码重用，保持目录的整洁。当前github上复用mmdetection代码开发实现的相关代码仓库中大多引用了不必要的代码，因此考虑从结构上简化。其中
<em>allow_failed_imports=False</em> 会在impoort的文件不存在的时候throw
error。</p>
<figure class="highlight python"><figcaption><span>mmdetection/config/solo.py</span></figcaption><table><tr><td class="code"><pre><span class="line">custom_imports = <span class="built_in">dict</span>(</span><br><span class="line">    imports=[</span><br><span class="line">        <span class="string">"custommd.models.detectors.single_stage_ins"</span>,</span><br><span class="line">        <span class="string">"custommd.models.detectors.solov2"</span>,</span><br><span class="line">        <span class="string">"custommd.models.solov2.mask_feat_head"</span>,</span><br><span class="line">        <span class="string">"custommd.models.solov2.solov2_head"</span>,</span><br><span class="line">    ],</span><br><span class="line">    allow_failed_imports=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>使用Wandb监控实验</li>
</ol>
<p>mmdetection框架中的wandb日志实现策略在<a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmcv/blob/83df7c4b00197b40c3debdb7f388a256640e13b4/mmcv/runner/hooks/logger/wandb.py">github</a>中能够找到,关于wandb的初始化参数可以参考<a target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/python/init">这里</a>,
配置文件中可以在<em>wandb_init_kwargs</em>中定义wandb的初始化参数。
<figure class="highlight python"><figcaption><span>mmdetection/config/model_config.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">log_config = <span class="built_in">dict</span>(</span><br><span class="line">            interval=<span class="number">10</span>,</span><br><span class="line">            hooks=[</span><br><span class="line">                <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'WandbLogger'</span>,</span><br><span class="line">                     wandb_init_kwargs={</span><br><span class="line">                         <span class="string">'entity'</span>: WANDB_ENTITY,</span><br><span class="line">                         <span class="string">'project'</span>: WANDB_PROJECT_NAME</span><br><span class="line">                     },</span><br><span class="line">                     logging_interval=<span class="number">10</span>,</span><br><span class="line">                     log_checkpoint=<span class="literal">True</span>,</span><br><span class="line">                     log_checkpoint_metadata=<span class="literal">True</span>,</span><br><span class="line">                     num_eval_images=<span class="number">100</span>)</span><br><span class="line">            ])</span><br></pre></td></tr></table></figure></p>
<ol start="3" type="1">
<li>使用timm中预训练的backbone</li>
</ol>
<p>mmdetection
中可以使用部分timm模型作为特征提取器，但是使用有所限制。使用timm库中的特征提取器需要指定使用的backbone类型。TIMMBackbone类型的具体定义在<em>mmcls.models</em>中。有两种方式可以实现，第一种是安装mmcls包后，使用其对TIMMBackbone的定义方式，显示的在config中的backbone部分制定，另一部分则是将<a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/open-mmlab/mmclassification/master/mmcls/models/backbones/base_backbone.py">basebackbone.py</a>文件和<a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmclassification/blob/master/mmcls/models/backbones/timm_backbone.py">timm_backbone.py</a>稍作修改，主要是对其中的get_root_logger()函数修改为修改为<code>from mmdet.utils import get_root_logger</code>,通过这两种引用方式可以实现在mmdetection中使用timm库中的预训练模型。默认情况下不使用预训练的权重，需要显式指定。支持更改权重所在的位置，可以使用在image21-k上预训练的模型权重。具体代码如下：</p>
<figure class="highlight python"><figcaption><span>mmdetection/config/model_config.py</span></figcaption><table><tr><td class="code"><pre><span class="line">custom_imports = <span class="built_in">dict</span>(imports=[<span class="string">'mmcls.models'</span>], allow_failed_imports=<span class="literal">False</span>)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">custom_imports = dict(imports=[</span></span><br><span class="line"><span class="string">    'mmdet.model.backbone.timm_backbone'</span></span><br><span class="line"><span class="string">    ], allow_failed_imports=False)</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = <span class="built_in">dict</span>(</span><br><span class="line">    backbone=<span class="built_in">dict</span>(</span><br><span class="line">        _delete_=<span class="literal">True</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">'mmcls.TIMMBackbone'</span>,</span><br><span class="line">        model_name=<span class="string">'tv_resnet50'</span>,  <span class="comment"># ResNet-50 with torchvision weights</span></span><br><span class="line">        features_only=<span class="literal">True</span>,</span><br><span class="line">        pretrained=<span class="literal">True</span>,</span><br><span class="line">        checkpoint_path=<span class="string">''</span>,</span><br><span class="line">        out_indices=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)))</span><br></pre></td></tr></table></figure>
<ol start="4" type="1">
<li><p>自定义<strong>Pipeline</strong>
mmdetection中Pipeline决定了数据加载到送入模型前的数据处理过程，同时，Pipeline本身具有一定的灵活性，这里推荐结合
<a target="_blank" rel="noopener" href="https://github.com/albumentations-team/albumentations">albumentations</a>
进行数据预处理，包含对bbox
的处理过程，保证增强后的图片和标签的一致性。各种增强方法图像变换前后的对比可以<a target="_blank" rel="noopener" href="https://albumentations-demo.herokuapp.com/">参考这里</a>
<figure class="highlight python"><figcaption><span>mmdetection/custom_models/albumentations.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> mmcls.datasets <span class="keyword">import</span> PIPELINES</span><br><span class="line"><span class="keyword">import</span> albumentations <span class="keyword">as</span> A</span><br><span class="line"></span><br><span class="line"><span class="meta">@PIPELINES.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RandomAlbumentationsV2</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, p=<span class="number">0.6</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.p = p</span><br><span class="line">        self.transform = A.Compose([</span><br><span class="line">            A.RandomGridShuffle(always_apply=<span class="literal">False</span>, p=self.p, grid=(<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">            A.CoarseDropout(</span><br><span class="line">                always_apply=<span class="literal">False</span>, p=<span class="number">1</span>,</span><br><span class="line">                max_holes=<span class="number">16</span>,</span><br><span class="line">                max_height=<span class="number">8</span>,</span><br><span class="line">                max_width=<span class="number">8</span>,</span><br><span class="line">            ),</span><br><span class="line">            A.Downscale(</span><br><span class="line">                always_apply=<span class="literal">False</span>, p=self.p,</span><br><span class="line">                scale_min=<span class="number">0.25</span>, scale_max=<span class="number">0.25</span>, interpolation=<span class="number">0</span></span><br><span class="line">            ),</span><br><span class="line"></span><br><span class="line">            A.ISONoise(</span><br><span class="line">                always_apply=<span class="literal">False</span>, p=<span class="number">0.9</span>,</span><br><span class="line">                intensity=(<span class="number">0.0</span>, <span class="number">0.5</span>),</span><br><span class="line">                color_shift=(<span class="number">0.0</span>, <span class="number">0.5</span>),</span><br><span class="line">            ),</span><br><span class="line">             A.JpegCompression(</span><br><span class="line">                always_apply=<span class="literal">False</span>, p=self.p,</span><br><span class="line">                quality_lower=<span class="number">80</span>,</span><br><span class="line">                quality_upper=<span class="number">100</span></span><br><span class="line">            ),</span><br><span class="line">            A.MotionBlur(</span><br><span class="line">                always_apply=<span class="literal">False</span>, p=self.p, </span><br><span class="line">                blur_limit=(<span class="number">3</span>, <span class="number">10</span>),</span><br><span class="line">            ),</span><br><span class="line">            A.MultiplicativeNoise(</span><br><span class="line">                always_apply=<span class="literal">False</span>, p=<span class="number">1.0</span>, multiplier=(<span class="number">0.1</span>, <span class="number">2.0</span>),</span><br><span class="line">                per_channel=<span class="literal">True</span>,</span><br><span class="line">                elementwise=<span class="literal">True</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        ])</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, results</span>):</span><br><span class="line">        img = results[<span class="string">'img'</span>]</span><br><span class="line">        transformed = self.transform(image=img)</span><br><span class="line">        results[<span class="string">'img'</span>] = transformed[<span class="string">"image"</span>]</span><br><span class="line">        <span class="keyword">return</span> results</span><br><span class="line"></span><br></pre></td></tr></table></figure> Pipeline
定义完成后，在config相应数据处理config片段中加入定义好的预处理方法即可
<figure class="highlight python"><figcaption><span>mmdetection/config/custom_config.py</span></figcaption><table><tr><td class="code"><pre><span class="line">train_pipeline = [</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'LoadImageFromFile'</span>),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'Resize'</span>,size=<span class="number">224</span>),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'RandomAlbumentationsV2'</span>), <span class="comment"># 这里为自定义pipeline的名称，可在dict内添加对应的参数</span></span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'RandomNoise'</span>),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'RandomFlip'</span>),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'Normalize'</span>, **img_norm_cfg),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'ImageToTensor'</span>, keys=[<span class="string">'img'</span>]),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'ToTensor'</span>, keys=[<span class="string">'gt_label'</span>]),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'Collect'</span>, keys=[<span class="string">'img'</span>, <span class="string">'gt_label'</span>])</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
检查Pipeline是否正确，这里可以使用mmdetection自带的工具对pipeline处理后的图像进行可视化处理。
<figure class="highlight bash"><figcaption><span>mmdetection/show_pipeline.sh</span></figcaption><table><tr><td class="code"><pre><span class="line">python tools/visualizations/vis_pipeline.py [config_path] --output-dir [out_dir_path] --number 20 --mode concat</span><br></pre></td></tr></table></figure></p></li>
<li><p>自动保存最好的ckpt文件 mmdetection中在evaluation
epoch中可按照相应的结果保存相应指标最好的权重文件，且可设置训练多少epoch时开始保存。其自带的权重保存机制支持限制保存文件的最大数量。对应代码如下：
<figure class="highlight python"><figcaption><span>mmdetection/config/custom_config.py</span></figcaption><table><tr><td class="code"><pre><span class="line">checkpoint_config = <span class="built_in">dict</span>(interval=<span class="number">50</span>, max_keep_ckpts=<span class="number">2</span>) <span class="comment"># 每50 epoch 保存一次，保存目录中最多存在两个权重文件，evaluation生成文件不包含在限制内</span></span><br><span class="line">evaluation = <span class="built_in">dict</span>(       <span class="comment"># evaluation hook 的配置</span></span><br><span class="line">    interval=<span class="number">4</span>,          <span class="comment"># 验证期间的间隔，单位为 epoch 或者 iter， 取决于 runner 类型。</span></span><br><span class="line">    metric=<span class="string">'accuracy'</span>,</span><br><span class="line">    save_best=<span class="string">'auto'</span>,</span><br><span class="line">    start=<span class="number">50</span></span><br><span class="line">    )   <span class="comment"># 验证期间使用的指标。</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>梯度累计 训练真实使用的batchsize为 samples_per_gpu *
cumulative_iters，此项设置会影响模型训练的流程，最好不使用。
<figure class="highlight python"><figcaption><span>mmdetection/config/custom_config.py</span></figcaption><table><tr><td class="code"><pre><span class="line">optimizer_config = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">"GradientCumulativeOptimizerHook"</span>, <span class="comment"># 累积倍数</span></span><br><span class="line">    cumulative_iters=<span class="number">4</span>,</span><br><span class="line">)</span><br><span class="line">data =<span class="built_in">dict</span>(</span><br><span class="line">    samples_per_gpu=<span class="number">64</span>, <span class="comment"># 基础batchsize</span></span><br><span class="line">）</span><br></pre></td></tr></table></figure></p></li>
<li><p>学习率调节和可视化
mmdetection中有几种内置的学习速率调节策略，基本通用型为使用CosineAnnealing且随epoch不断变化的学习速率设置。如下代码，target_ratio决定了最大和最小两次的学习率倍数，这里设置学习率随着epoch不断变化。
<figure class="highlight python"><figcaption><span>mmdetection/config/custom_config.py</span></figcaption><table><tr><td class="code"><pre><span class="line">lr_config = <span class="built_in">dict</span>(</span><br><span class="line">    policy=<span class="string">'cyclic'</span>,</span><br><span class="line">    target_ratio= (<span class="number">2e3</span>, <span class="number">1e-2</span>), <span class="comment"># 决定了最大学习率倍数，实际最大值为 target_ratio[0] * lr</span></span><br><span class="line">    cyclic_times= <span class="number">5</span>, <span class="comment"># 训练开始到训练结束共调整五次</span></span><br><span class="line">    step_ratio_up= <span class="number">0.4</span>, <span class="comment"># real lr = warmup_ratio * initial lr</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">optimizer = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">'AdamW'</span>,</span><br><span class="line">    lr=<span class="number">5e-4</span> * <span class="number">128</span> * <span class="number">4</span> / <span class="number">512</span> * <span class="number">1e-4</span>, <span class="comment"># 决定了 baselr</span></span><br><span class="line">    weight_decay=<span class="number">0.0001</span>,</span><br><span class="line">    eps=<span class="number">1e-8</span>,</span><br><span class="line">    betas=(<span class="number">0.9</span>, <span class="number">0.999</span>),)</span><br></pre></td></tr></table></figure>
mmdetection中自带学习率可视化工具，可以根据config文件对学习率可视化，方便调整。
<figure class="highlight bash"><figcaption><span>mmdetection/show_lr.sh</span></figcaption><table><tr><td class="code"><pre><span class="line">python tools/visualizations/vis_lr.py [config_path] --save-path [output_path]</span><br></pre></td></tr></table></figure></p></li>
<li><p>Mixup &amp; CutPaste mmcls中支持两个比较特殊的数据增强策略，Mixup
和 CutPaste,通常结合 LabelSmoothLoss。 <figure class="highlight python"><figcaption><span>mmdetection/config/resnet.py</span></figcaption><table><tr><td class="code"><pre><span class="line">model = <span class="built_in">dict</span>(</span><br><span class="line">    backbone = ...,</span><br><span class="line">    neck = ...,</span><br><span class="line">    head = ...,</span><br><span class="line">    train_cfg=<span class="built_in">dict</span>(augments=[</span><br><span class="line">        <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'BatchMixup'</span>, alpha=<span class="number">0.8</span>, prob=<span class="number">0.5</span>, num_classes=num_classes),</span><br><span class="line">        <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'BatchCutMix'</span>, alpha=<span class="number">1.0</span>, prob=<span class="number">0.5</span>, num_classes=num_classes),</span><br><span class="line">    ]))</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p></li>
<li><p>多卡 batch norm同步设置 有两种可用的batch norm sync
设置，MMSyncBN和SyncBN,MMSyncBN为实验功能，缺少相关文档介绍。
<figure class="highlight python"><figcaption><span>mmdetection/config/base.py</span></figcaption><table><tr><td class="code"><pre><span class="line">norm_cfg=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">'MMSyncBN'</span>, requires_grad=<span class="literal">True</span>) <span class="comment"># or type='SyncBN'</span></span><br></pre></td></tr></table></figure></p></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>





</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YiQing Hao</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Symbols count total">16k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">14 mins.</span>
  </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","mhchem":false,"js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
