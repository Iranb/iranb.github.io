<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"iranb.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.11.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="总结一些深度模型常用的调试优化技巧。 0x01 探索性数据分析 EDA(Exploratory Data Analysis)  数据分布分析 主要判断训练数据中存在的各类数据与其样本占训练数据占比，通常存在两种分布：均匀分布和长尾分布 ## 0x02 正则化 常用方法  Z score Normalization（mean std Standardization）    - Min-Max Sca">
<meta property="og:type" content="article">
<meta property="og:title" content="how_to_finetune">
<meta property="og:url" content="https://iranb.github.io/2022/09/13/how-to-finetune/index.html">
<meta property="og:site_name" content="Road to Stain‘s Gate">
<meta property="og:description" content="总结一些深度模型常用的调试优化技巧。 0x01 探索性数据分析 EDA(Exploratory Data Analysis)  数据分布分析 主要判断训练数据中存在的各类数据与其样本占训练数据占比，通常存在两种分布：均匀分布和长尾分布 ## 0x02 正则化 常用方法  Z score Normalization（mean std Standardization）    - Min-Max Sca">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://iranb.github.io/2022/09/13/how-to-finetune/normlize.png">
<meta property="og:image" content="https://iranb.github.io/2022/09/13/how-to-finetune/FLower.png">
<meta property="og:image" content="https://iranb.github.io/2022/09/13/how-to-finetune/car.png">
<meta property="og:image" content="https://iranb.github.io/2022/09/13/how-to-finetune/dogs.png">
<meta property="og:image" content="https://iranb.github.io/2022/09/13/how-to-finetune/result_512.jpg">
<meta property="og:image" content="https://iranb.github.io/2022/09/13/how-to-finetune/result_128.jpg">
<meta property="og:image" content="https://iranb.github.io/2022/09/13/how-to-finetune/self_train_1.png">
<meta property="og:image" content="https://iranb.github.io/2022/09/13/how-to-finetune/self_train_2.png">
<meta property="article:published_time" content="2022-09-13T02:14:20.000Z">
<meta property="article:modified_time" content="2022-10-13T06:41:12.945Z">
<meta property="article:author" content="YiQing Hao">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://iranb.github.io/2022/09/13/how-to-finetune/normlize.png">


<link rel="canonical" href="https://iranb.github.io/2022/09/13/how-to-finetune/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://iranb.github.io/2022/09/13/how-to-finetune/","path":"2022/09/13/how-to-finetune/","title":"how_to_finetune"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>how_to_finetune | Road to Stain‘s Gate</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Road to Stain‘s Gate</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#x01-%E6%8E%A2%E7%B4%A2%E6%80%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-edaexploratory-data-analysis"><span class="nav-number">1.</span> <span class="nav-text">0x01
探索性数据分析 EDA(Exploratory Data Analysis)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#xfe-psedu-label"><span class="nav-number">2.</span> <span class="nav-text">0xFe: Psedu label</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#xff-references"><span class="nav-number">3.</span> <span class="nav-text">0xFF: References</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">YiQing Hao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://iranb.github.io/2022/09/13/how-to-finetune/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="YiQing Hao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="how_to_finetune | Road to Stain‘s Gate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          how_to_finetune
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-09-13 10:14:20" itemprop="dateCreated datePublished" datetime="2022-09-13T10:14:20+08:00">2022-09-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-10-13 14:41:12" itemprop="dateModified" datetime="2022-10-13T14:41:12+08:00">2022-10-13</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>3.7k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>3 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>总结一些深度模型常用的调试优化技巧。</p>
<h2 id="x01-探索性数据分析-edaexploratory-data-analysis">0x01
探索性数据分析 EDA(Exploratory Data Analysis)</h2>
<ol type="1">
<li>数据分布分析
主要判断训练数据中存在的各类数据与其样本占训练数据占比，通常存在两种分布：均匀分布和长尾分布
## 0x02 正则化</li>
<li>常用方法
<ul>
<li>Z score Normalization（mean std Standardization）</li>
</ul></li>
</ol>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.577ex;" xmlns="http://www.w3.org/2000/svg" width="6.349ex" height="4.824ex" role="img" focusable="false" viewbox="0 -1435 2806.4 2132"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(794.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/></g><g data-mml-node="mover" transform="translate(1794.4,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"/></g><g data-mml-node="mo" transform="translate(0,374)"><svg width="572" height="237" x="0" y="148" viewbox="143 148 572 237"><path data-c="2013" d="M0 248V285H499V248H0Z" transform="scale(1.716,1)"/></svg></g></g></g><g data-mml-node="mi" transform="translate(1117.7,-686)"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"/></g><rect width="2566.4" height="60" x="120" y="220"/></g></g></g></svg></mjx-container></span></p>
<pre><code>- Min-Max Scaling
- Standard Deviation Method
- Range Method
- RankGauss(top1-recon)
通常RankGauss的效果也会比标准化和归一化好</code></pre>
<figure class="highlight python"><figcaption><span>mmdetection/rankgauss</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> erfinv</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scale_minmax</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="string">'''归一化'''</span></span><br><span class="line">    <span class="keyword">return</span> (x - x.<span class="built_in">min</span>()) / (x.<span class="built_in">max</span>() - x.<span class="built_in">min</span>())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scale_norm</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="string">'''标准化'''</span></span><br><span class="line">    <span class="keyword">return</span> (x - x.mean()) / x.std()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scale_rankgauss</span>(<span class="params">x, epsilon=<span class="number">1e-6</span></span>):</span><br><span class="line">    <span class="string">'''rankgauss'''</span></span><br><span class="line">    x = x.argsort().argsort() <span class="comment"># rank</span></span><br><span class="line">    x = (x/x.<span class="built_in">max</span>()-<span class="number">0.5</span>)*<span class="number">2</span> <span class="comment"># scale</span></span><br><span class="line">    x = np.clip(x, -<span class="number">1</span>+epsilon, <span class="number">1</span>-epsilon)</span><br><span class="line">    x = erfinv(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>为什么需要使用正则化方法
<ul>
<li>For Cluster
Analysis：通常情况需要度量不同输入间的距离，未正则化数据可能会存在特殊极值影响度量结果。</li>
<li>For Principal Component Analysis：PCA gives more weightage to those
variables that have higher variances than to those variables that have
very low variances（方差会影响降维结果）</li>
<li>正则化能改变输入数据的分布，在数据预处理时通常包含两个步骤：Scaling
&amp; Normalize， Scaling负责将输入数据映射到0-1范围内，Scaling can help
compare different variables on equal
footing（在同样的步长上比较两个数据）;
Normalization本质上是一种激进的策略，The point of normalization is to
change your observations so that they can be described as a normal
distribution.Normalization能够改变模型观察数据的角度，使输入数据可以被描述为一个正态分布。</li>
<li>Scaling(归一化)消除特征间单位和尺度差异的影响，以对每维特征同等看待，需要对特征进行归一化。</li>
<li>因尺度差异，其损失函数的等高线图可能是椭圆形，梯度方向垂直于等高线,变换后，其损失函数的等高线图更接近圆形，梯度下降的方向震荡更小，收敛更快</li>
<li>随着训练程度加深，模型复杂度会增加，偏差减少，方差增大，而泛化误差呈现
U
型变化，对于一个“好的系统”通常要求误差小，正则化的作用即为适当的控制模型复杂度，从而使得泛化误差曲线取最小值<img src="/2022/09/13/how-to-finetune/normlize.png" alt="如图">，从贝叶斯角度考虑，正则项等价于引入参数的模型先验概率，可以简单理解为对最大似然估计（MLE）引入先验概率，从而转化为最大后验估计（MAP），其中的先验概率即对于正则项
## 0x03: 如何选择CNN输入图像的尺寸</li>
</ul></li>
<li>ImageNet
上预训练的backbone模型通常在224x224大小的输入图像上进行预训练，这并不意味着我们需要将输入图像resize到224x224大小</li>
<li>以224x224大小的输入数据为例，假设输入图像经过网络输出的特征图大小为原始图像的<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.816ex;" xmlns="http://www.w3.org/2000/svg" width="2.595ex" height="2.773ex" role="img" focusable="false" viewbox="0 -864.9 1147.1 1225.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mn" transform="translate(396.8,394) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="mn" transform="translate(220,-345) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"/><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"/></g><rect width="907.1" height="60" x="120" y="220"/></g></g></g></svg></mjx-container></span>,如果将输入图像尺寸增大到512x512,则对应的输出特征图大小从7x7变为16x16，特征图的输出大小仅与网络本身结构和输入的图像大小有关。</li>
<li>在模型中，与预训练尺寸有关的是网络从确定大小物体中学习到的固定模式，例如从输入图像中寻找直径为50个像素大小的圆，或是边长为30个像素的三角形。以下三个图为例
<img src="/2022/09/13/how-to-finetune/FLower.png" alt="FLower"> <img src="/2022/09/13/how-to-finetune/car.png" alt="car">
<img src="/2022/09/13/how-to-finetune/dogs.png" alt="Dogs"></li>
<li>假设将输入图像大小放大到512x512会发生什么：放缩输入图像的大小等价于放缩图像中的物体，CNN可能找不到直径50的圆和边长30的三角形。
<img src="/2022/09/13/how-to-finetune/result_512.jpg" alt="result_512">
如果图像尺寸缩小到128，模型可能找不到其中的圆 <img src="/2022/09/13/how-to-finetune/result_128.jpg" alt="result_128"></li>
<li>结论
CNN能从图像中搜索固定的模式（patterns），这些固定的模式可能和图像的尺寸相关，因此需要通过实验寻找不同模式对应的inputsize，
或者融合多尺度特征。 ## 0x04 DataAugmentation</li>
<li>CutMix 公式如下: <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="75.566ex" height="2.149ex" role="img" focusable="false" viewbox="0 -750 33400 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="merror" data-mjx-error="Unknown environment 'itemize'" title="Unknown environment 'itemize'"><rect data-background="true" width="33400" height="950" y="-200"/><title>Unknown environment 'itemize'</title><g data-mml-node="mtext" style="font-family: serif;"><text data-variant="-explicitFont" transform="scale(1,-1)" font-size="884px"> \begin{itemize} \item[$\bullet$] 文字内容 \end{itemize} </text></g></g></g></g></svg></mjx-container></span></li>
</ol>
<figure class="highlight python"><figcaption><span>feature_cutmix.py</span></figcaption><table><tr><td class="code"><pre><span class="line">x = self.layer1(x)</span><br><span class="line">bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)</span><br><span class="line">x[:,:,bbx1:bbx2,bby1:bby2] = x[rand_index,:,bbx1:bbx2,bby1:bby2]</span><br><span class="line">x = self.layer2(x)</span><br><span class="line"><span class="comment"># if you use activate fun like ReLU, change inplace=True to inplace=False</span></span><br><span class="line"><span class="number">2.</span> Mixup</span><br></pre></td></tr></table></figure>
<h2 id="xfe-psedu-label">0xFe: Psedu label</h2>
<ol start="0" type="1">
<li>Psedu label有效的一些原理上的解释
<ul>
<li>根据聚类假设（cluster
assumption），这些概率较高的点，通常在相同类别的可能性较大，所以其pseudo-label是可信度非常高的。（合理性）</li>
<li>熵正则化是在最大后验估计框架内从未标记数据中获取信息的一种方法，通过最小化未标记数据的类概率的条件熵，促进了类之间的低密度分离，而无需对密度进行任何建模，通过熵正则化与伪标签具有相同的作用效果，都是希望利用未标签数据的分布的重叠程度的信息。（有效性）</li>
<li>值得注意的是：当场景不满足 聚类假设
、熵正则化失效（样本空间覆盖密集）情况下，伪标签技术很有可能失效。</li>
<li>缺点：容易在有限的测试集上过拟合</li>
</ul></li>
<li>Psedu
label的主要思想来自于Self-Training，其实现思路是找到一种方法用未标记的数据集来扩充已标记的数据集，主要流程如下：
<ul>
<li>利用已标记的数据来训练一个好的模型，然后使用这个模型对未标记的数据进行标记</li>
<li>利用训练好的标签信息在无标签数据上进行推理，使用分数阈值（confidence
score）或其他方法从无标签数据的推理结果中过滤出可靠的标签，以选择出未标记数据的预测标签的一个子集</li>
<li>将生成的伪标签与原始的标记数据相结合，并在合并后数据上进行联合训练</li>
<li>整个过程不断重复，直到无标签数据的置信度不再上升</li>
</ul></li>
<li>伪标签往往会向模型的优化数据中混入大量噪声，使模型朝着错误的方向优化，因此需要设计一些策略解决噪声问题：
<ul>
<li>添加label smooth
，使伪标签带来的错误之心度不在sharp，从而减小错误标签导致的噪声问题 <img src="/2022/09/13/how-to-finetune/self_train_1.png" alt="selftrain"></li>
<li>打标签的过程中添加 label regularization (LR)，增加 pesudo label
的熵，类似于 label smooth 的作用</li>
<li>网络重新训练的过程中添加 model regularization
(MR)，增加网络输出概率的熵</li>
<li>使用 masked model,在模型中添加dropout，对于选出的每个 unlabeled
的数据，我们可以将其传入 N次得到不同的 T
个预测结果，直接将预测结果求平均就得到了预测标签</li>
<li>先对每个类选择相同数目的样本，防止某些类特别容易造成的样本极度不均衡。然后在每个类中使用
BALD（Bayesian Active Learning by Disagreement（BALD））
对样本进行排名并依概率抽取。如果我们想要挖掘简单样本就以 1-BALD
排名，否则以 BALD 排名，BALD有两种模式，类似数据增强 <img src="/2022/09/13/how-to-finetune/self_train_2.png" alt="self_train_2"></li>
<li>Confident
Learning：然后分别计算预测结果的均值和方差，使用模型预测的方差来对损失进行加权，目的是给与方差小的伪标注样本更大的权重</li>
</ul></li>
</ol>
<h2 id="xff-references">0xFF: References</h2>
<p>[1]: <a target="_blank" rel="noopener" href="https://github.com/vandit15/Class-balanced-loss-pytorch">Class-balanced-loss-pytorch</a><br>
[2]: <a target="_blank" rel="noopener" href="https://www.kaggle.com/discussions/questions-and-answers/59305">When
and why to standardize or normalize a variable?</a><br>
[3]: <a target="_blank" rel="noopener" href="https://www.kaggle.com/code/rtatman/data-cleaning-challenge-scale-and-normalize-data/notebook">Data
Cleaning Challenge: Scale and Normalize Data</a><br>
[4]: <a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/siim-isic-melanoma-classification/discussion/160147">CNN
Input Size Explained</a><br>
[5]: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/330333894">RankGauss</a><br>
[n-1]: <a target="_blank" rel="noopener" href="https://scholar.google.com/scholar_url?url=https://www.kaggle.com/blobs/download/forum-message-attachment-files/746/pseudo_label_final.pdf&amp;hl=zh-CN&amp;sa=T&amp;oi=gsb-gga&amp;ct=res&amp;cd=0&amp;d=16547318329102522555&amp;ei=8GAoY57_CLaQ6rQP-NO84AU&amp;scisig=AAGBfm00HNXM--PNcdJRi04oq0tThe466g">Pseudo-Label
: The Simple and Efficient Semi-Supervised Learning Method for Deep
Neural Networks</a> [n]: <a target="_blank" rel="noopener" href="https://helicqin.github.io/2021/03/18/Self-Training%E7%BB%BC%E8%BF%B0/">Self
Training</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/pytorch/" rel="tag"># pytorch</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/05/17/reveal-md/" rel="prev" title="reveal-md">
                  <i class="fa fa-chevron-left"></i> reveal-md
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/09/13/kaggle-top-player-notes/" rel="next" title="kaggle top player notes">
                  kaggle top player notes <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YiQing Hao</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Symbols count total">12k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">11 mins.</span>
  </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","mhchem":false,"js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
